---
title: MySQL八股补充
date: 2024-11-12 10:21:00 +0800
categories: [数据库, 八股]
tags: [数据库,MySQL,八股]
---



## 1. 索引

**为什么假设读一个结点就是一次磁盘IO？**

1. 考虑的是最坏情况

2. 与树的数据结构对应。树的一个结点独享一片磁盘空间，而不是多个结点共享一片空间。对应物理存储中，一个页只存一个结点（一行）

3. 所有数据类型都假设读一个结点就是一次磁盘IO，可以简化问题

4. 即使不假设读一个结点就是一次磁盘IO，即多个结点放在一个页中，当数据量大时或删改多了时，也相当于一页一结点了。

   > 例如，Id为10，11，12，13，14，15的结点都存在一页里面并且存满了这一页，然后再插入Id为5的结点到新一页。再把Id为11，12，13，14，15的结点删去。那么就是Id为10与Id为5的两个结点在两页里面。



**如何定位慢查询？**

- 方案一：skywalking等运维工具

- 方案二：MySQL自带的慢查询日志

  ![image-20241120183006812](assets/2024-11-12-AddictionToMySQL.assets/image-20241120183006812.png)

  > 一般调试阶段才开，生产环境不开。



**那这个SQL语句执行很慢，如何分析呢？**

如果一条SQL执行很慢，我们通常会使用MySQL的`EXPLAIN`命令来分析这条SQL的执行情况。通过`key`和`key_len`可以检查是否命中了索引，如果已经添加了索引，也可以判断索引是否有效。通过`type`字段可以查看SQL是否有优化空间，比如是否存在全索引扫描或全表扫描。通过`extra`建议可以判断是否出现回表情况，如果出现，可以尝试添加索引或修改返回字段来优化。



**MySQL超大分页怎么处理？**

超大分页通常发生在数据量大的情况下，使用`LIMIT`分页查询且需要排序时效率较低。可以通过覆盖索引和子查询来解决。首先查询数据的ID字段进行分页，然后根据ID列表用子查询来过滤只查询这些ID的数据，因为查询ID时使用的是覆盖索引，所以效率可以提升。

>### 场景假设
>
>假设有一个`articles`表，包含如下字段：
>
>- `id`（主键）
>- `title`（文章标题）
>- `content`（文章内容）
>- `created_at`（创建时间）
>
>我们希望分页获取第100,001到100,020条文章，并按`created_at`降序排列。
>
>---
>
>### 初始查询（未优化）
>
>常规分页查询会这样写：
>
>```sql
>SELECT id, title, content, created_at
>FROM articles
>ORDER BY created_at DESC
>LIMIT 100000, 20;
>```
>
>> `created_at`建立了一个索引
>
>**问题：**
>
>- 当偏移量（`OFFSET`）很大时，MySQL仍需要多次回表查询扫描大量行并丢弃前面的数据，导致性能下降。
>
>---
>
>### 优化方案：覆盖索引 + 子查询
>
>#### 0. 为`created_at`建立索引
>
>#### 1. 首先查询需要的`id`列表
>
>利用覆盖索引（需要查询的列在索引中可以找到避免回表查询或查询聚簇索引的叶子节点的data域）只读取`id`字段：
>
>```sql
>SELECT id
>FROM articles
>ORDER BY created_at DESC
>LIMIT 100000, 20;
>```
>
>#### 2. 根据ID列表获取完整数据
>
>将上一步的结果作为子查询：
>
>```sql
>SELECT id, title, content, created_at
>FROM articles
>WHERE id IN (
>   SELECT id
>   FROM articles
>   ORDER BY created_at DESC
>   LIMIT 100000, 20
>)
>ORDER BY created_at DESC;
>```
>
>---
>
>### 为什么性能更高？
>
>1. **覆盖索引减少了IO开销**：子查询中只扫描索引，而不读取完整的行数据。
>2. **减少无效扫描**：主查询直接根据ID列表获取行，避免了全表扫描。
>
>---
>
>### 进一步优化（主键联合）
>
>如果主键是`(created_at, id)`，查询可以更高效：
>
>```sql
>SELECT id, title, content, created_at
>FROM articles AS a
>JOIN (
>   SELECT id
>   FROM articles
>   ORDER BY created_at DESC
>   LIMIT 100000, 20
>) AS sub ON a.id = sub.id
>ORDER BY a.created_at DESC;
>```
>
>这种方式能充分利用索引优化，同时避免了大偏移量导致的性能问题。
>
>### 注意事项
>
>- 确保`created_at`字段已加索引。
>- 如果查询频繁，考虑引入**延迟分页**或**按游标分页（cursor-based pagination）**，通过保存最后一页的标记点继续查询，进一步提升效率。



**索引创建原则有哪些？**

创建索引的原则包括：

- 表中的数据量超过10万以上时考虑创建索引。
- 选择查询频繁的字段作为索引，如查询条件、排序字段或分组字段。
- 尽量使用复合索引，覆盖SQL的返回值。
- 如果字段区分度不高，可以将其放在组合索引的后面。
- 对于内容较长的字段，考虑使用前缀索引。
- 控制索引数量，因为索引虽然可以提高查询速度，但也会影响插入、更新的速度。



**创建表的时候，你们是如何优化的呢？**

创建表时，我们主要参考《嵩山版》开发手册，选择字段类型时结合字段内容，比如数值类型选择`TINYINT`、`INT`、`BIGINT`等，字符串类型选择`CHAR`、`VARCHAR`或`TEXT`。



**在使用索引的时候，是如何优化呢？**

在使用索引时，我们遵循索引创建原则，确保索引字段是查询频繁的，使用复合索引覆盖SQL返回值，避免在索引字段上进行运算或类型转换，以及控制索引数量。



**你平时对SQL语句做了哪些优化呢？**

- 指明字段名称而不是使用`SELECT *`

  > select 字段有时候可以用到覆盖索引优化，select *则一定会回表

- 避免造成索引失效的写法

- 聚合查询时使用`UNION ALL`代替`UNION`

  > union比union all多一次过滤操作
  >
  > > 例如`select id from user where id > 5 union select id from user where id < 10 `会把id为(5,10)的展示两次，
  > >
  > > 而`select id from user where id > 5 union all select id from user where id < 10 `只展示所有id一次，即不会过滤重复

- 表关联时优先使用`INNER JOIN`，以及在必须使用`LEFT JOIN`或`RIGHT JOIN`时，确保小表作为驱动表

  > 内连接会对两个表进行优化，优先把小表放到外边，把大表放到里边。leftjoin 或 right join，不会重新调整顺序

- 主从复制、读写分离

  > 如果数据库的使用场景读的操作比较多的时候，为了避免写的操作所造成的性能影响，可以采用读写分离的架构。
  > 读写分离解决的是，数据库的写入，影响了查询的效率。



## 2. 锁

**MySQL行级锁加锁范围的设计依赖：**

1. 加锁的对象是索引

   > 索引不存在就无法对它加锁

2. 加锁是为了防止脏读，不可重复读，幻读，防止读到的数据条数多了或者少了

3. 加锁的基本单位是`next-key lock`，next-lock key退化可以理解为在不可能影响查询结果集的前提下尽量便利其他查询

4. **插入语句在插入一条记录之前，需要先定位到该记录在 B+树 的位置（主键索引B+树或二级索引B+树），如果插入的位置的下一条记录的索引上有间隙锁（grap lock），才会发生阻塞**

   > 因为当我们执行插入语句时，会在插入间隙上获取插入意向锁，而插入意向锁与间隙锁是冲突的，所以当其它事务持有该间隙的间隙锁时，需要等待其它事务释放间隙锁之后，才能获取到插入意向锁。而间隙锁与间隙锁之间是兼容的，所以所以两个事务中`select ... for update` 语句并不会相互影响

5. 某记录加上记录锁只是保证这一行不被修改或删除，不保证不插入相同索引的一行；间隙锁只能防止插入

   > 例如对二级索引`age = 20`（id = 10）加锁，只代表id = 10这一行不被修改或删除，并不意味这不能再插入age = 20的一行



**Insert语句加锁**

![image-20241120105055844](assets/2024-11-12-AddictionToMySQL.assets/image-20241120105055844.png)

























