# 03. 现代特性：数值空间与向量检索

> **摘要**：Elasticsearch 早已超越了单纯的“文本搜索引擎”。随着 Lucene 6.0 引入 BKD-Tree 以及 9.0 引入 HNSW，ES 补齐了在多维数值分析和 AI 向量检索（Semantic Search）领域的短板。本章将深入内核，解析这两个支撑现代 ES “多模态检索”能力的底层数据结构。

---

## 1. BKD-Tree：数值与空间数据的革命

在 ES 5.0 之前，数值类型（Long/Integer/Double）采用的是 **TrieRange** 策略。即把数字当成字符串前缀来索引（`123` -> `term: 1-hundreds`, `term: 12-tens`）。
*   **痛点**：词项数量爆炸（Term Explosion），且范围查询性能随范围大小线性下降。
*   **变革**：Lucene 6.0 引入了 **BKD-Tree (Block K-D Tree)**，这是一种针对磁盘 IO 优化的多维空间索引结构。

### 1.1 核心算法：多维自适应切分

BKD-Tree 是一种平衡树，旨在将 N 维空间的数据点递归地划分为一个个矩形块（Block）。

#### 1.1.1 动态维度选择 (Adaptive Dimension Selection)
与标准 K-D Tree 轮流选择维度（X -> Y -> X）不同，BKD 在每次分裂节点时，会计算当前节点内数据在所有维度上的**方差（Variance）**或范围跨度。
*   **策略**：始终选择数据分布**最宽**（Spread 最大）的那个维度进行切分。
*   **目的**：使得生成的子空间尽可能接近“正方形”或“正方体”。
*   **收益**：对于地理位置（Geo-Point）数据，这意味着它能自适应地处理数据分布不均的情况（如某些数据在经度上分布广，某些在纬度上分布广），从而在 `geo_bounding_box` 查询时减少需要扫描的 Block 数量。

### 1.2 磁盘布局：Block Packing

BKD 树采用了“内部节点内存化 + 叶子节点磁盘化”的分离存储设计，极度适合 OS Page Cache。

1.  **内部节点 (Index File, .dii)**：
    *   存储完整的完全二叉树结构（Packed Binary Tree）。
    *   每个节点只记录：**切分维度**、**切分值**、**左子树的文件指针**。
    *   **极致紧凑**：通常完全加载到 JVM Heap 中，用于快速定位目标 Block。
2.  **叶子节点 (Data File, .dim)**：
    *   当递归切分导致子空间内的点数少于阈值（默认 **1024** 个点）时，停止切分。
    *   该节点内的所有点（1024个）被打包为一个 Block，写入磁盘。
    *   **Common Prefix Compression**：如果 Block 内所有点的数值高位相同，只存储低位，进一步压缩体积。

### 1.3 范围查询的高效执行
当执行 `age > 20 AND age < 30` 查询时：
1.  **Pruning (剪枝)**：内存中的 Index 快速判断某些子树是否完全在 `[20, 30]` 范围之外。是则跳过。
2.  **Fully Contained (全含)**：如果某子树范围完全在 `[20, 30]` 内，该子树下所有 DocID 直接加入结果集（**无需读取磁盘**，因为 DocID 可以在 Index 中预存或通过 Block 元数据获取）。
3.  **Intersection (相交)**：仅当 Block 的空间范围与查询范围边界相交时，才读取磁盘 Block 并逐个过滤。
> **性能对比**：实测表明，BKD 树使得数值范围查询性能比旧版 TrieRange 提升了 **300% - 500%**。

---

## 2. 向量检索：HNSW 图索引

在 RAG（检索增强生成）和 AI 搜索场景下，我们需要根据**语义相似度**（向量距离）来召回文档，而不仅仅是关键词匹配。

### 2.1 倒排索引的局限性
倒排索引是基于**精确匹配（Exact Match）**的。
*   搜索 "apple"，倒排表里有就有，没有就没有。
*   向量搜索要求的是 Top-K 近邻（K-NN）。给定查询向量 $V_q$，找出距离最近的 $K$ 个文档向量 $V_d$。
*   **暴力法 (Brute Force)**：计算 $V_q$ 与索引中所有 10 亿个向量的距离，耗时不可接受。

### 2.2 HNSW (Hierarchical Navigable Small World)

ES 8.x 深度集成了 Lucene 的 HNSW 实现。这是一种目前业界公认性能最优的近似最近邻（ANN）算法之一。

#### 2.2.1 结构：多层图 (Hierarchical Graph)
HNSW 借鉴了**跳表（Skip List）**的分层思想，构建了多层图结构：
*   **Layer 0 (底层)**：包含**所有**数据点的基图。节点间连接紧密（Short-range links），类似于“社区街道”。
*   **Layer N (顶层)**：只包含**少量**数据点（作为入口）。节点间连接稀疏（Long-range links），类似于“高速公路”。

#### 2.2.2 搜索流程：从高速到街道
1.  **Entry Point**：从顶层的一个入口点开始。
2.  **Greedy Search**：在当前层贪婪地向目标向量移动（计算邻居距离，谁近就跳到谁）。
3.  **Descend**：当在当前层无法找到更近的节点时，**下沉**到下一层，以上一层找到的最近点作为起点继续贪婪搜索。
4.  **Refinement**：最终在 Layer 0 进行精细搜索，收集 Top-K 候选集。

#### 2.2.3 关键参数与权衡
*   **`m` (Number of Connections)**：每个节点的最大连接边数。
    *   $M$ 越大，图越连通，召回率（Recall）越高，但内存消耗大，写入慢。
*   **`ef_construction`**：构建索引时的搜索深度（候选队列大小）。
    *   值越大，索引质量越高（图的连通性越好），但构建时间越长。
*   **`ef_search`**：查询时的搜索深度。
    *   值越大，召回率越高，但 QPS 越低。

### 2.3 内存与存储开销 (.vec / .vex)
*   **向量数据 (.vec)**：存储原始的浮点数组（Raw Floats）。
*   **图索引 (.vex)**：存储 HNSW 的图结构（邻接表）。
*   **内存大户**：HNSW 为了高性能，倾向于将图结构缓存在内存中。对于 10 亿级 768 维向量，索引可能占用数百 GB 内存。ES 利用 **Off-heap** 内存（MMap）来加载这些图，避免 JVM GC 压力，但对物理内存容量提出了硬性要求。

---

## 3. 混合搜索 (Hybrid Search)：ES 的杀手锏

这是 ES 相比 Milvus、Pinecone 等专用向量数据库最大的优势：**多模态融合**。

### 3.1 预过滤 (Pre-filtering) 策略
用户查询往往是：“查找 *2023年发布的* (Filter) *关于 LLM 的论文* (Vector)”。

*   **专用向量库的痛点**：通常支持较弱的标量过滤，或者采用 Post-filtering（先搜出 Top-K 向量，再过滤年份，可能导致结果不足 K 个）。
*   **ES 的策略**：利用倒排索引的高效过滤能力。
    1.  **BitSet 生成**：利用 Roaring Bitmap 快速找出“2023年”的文档 ID 集合 $S_{filter}$。
    2.  **受限遍历**：在 HNSW 图的遍历过程中，只考虑属于 $S_{filter}$ 的节点（或者在搜索结果候选集中快速验证位图）。
    3.  **结果**：既保证了语义相似度，又严格满足了业务过滤条件，且性能极高。

通过结合 **倒排索引 (精确过滤)** + **BKD (数值范围)** + **HNSW (语义相似)**，ES 实现了真正的“多模态检索”。