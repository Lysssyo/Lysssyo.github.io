# 02. 微观存储：倒排索引与压缩算法

> **摘要**：Elasticsearch 的高性能查询并非魔法，而是源于底层 Lucene 对磁盘数据结构的极致压榨。本章我们将显微镜对准磁盘文件，完整还原从“搜索词”到“JSON文档”的每一次磁盘跳转（Pointer Chasing），并深度剖析 FST、FOR、Roaring Bitmaps 以及行式存储压缩算法。

---

## 1. 全链路解析：从 Term 到 JSON (The Retrieval Chain)

当用户执行搜索 `GET /_search?q=elastic` 时，ES 内部发生了一场精密的接力赛。这不仅涉及倒排索引，还涉及正向存储。以下是完整的 **4 步跳转流程**：

### Step 1: 内存快速定位 (FST -> .tip)
*   **动作**：系统在堆内存（On-heap）或堆外内存（Off-heap）中查询 **Term Index (.tip)**。
*   **结构**：**FST (Finite State Transducer)**。
*   **输入**：关键词 "elastic"。
*   **输出**：该词在磁盘词典文件（.tim）中的**Block 偏移量**。
*   **意义**：FST 是“索引的索引”，它不存完整的词，只存前缀。它让系统知道：“'elastic' 这个词如果存在，大概率在 .tim 文件的第 1024 号 Block 里”。

### Step 2: 磁盘精确查找 (.tim)
*   **动作**：利用 FST 给出的偏移量，随机 I/O 读取磁盘上的 **Term Dictionary (.tim)** Block。
*   **结构**：**BlockTree**（排序的词项块）。
*   **过程**：解压该 Block，扫描找到确切的词项 "elastic"。
*   **输出**：
    1.  **DocFreq**：文档频率（有多少文档包含它）。
    2.  **Postings Pointer**：指向倒排表文件（.doc）的指针。
    3.  **Pos/Pay Pointer**：指向位置/负载文件（.pos, .pay）的指针。

### Step 3: 读取倒排表与解压 (.doc / .pos)
*   **动作**：根据指针读取 **Postings List (.doc)**。
*   **结构**：使用 **FOR (Frame of Reference)** 算法压缩的文档 ID 列表。
*   **过程**：CPU 利用 SIMD 指令将压缩数据还原为文档 ID 序列 `[10, 25, 33...]`。
*   **补充 (.pos/.pay)**：
    *   如果查询包含**短语搜索**（如 "elastic search"），还需要读取 **.pos (Positions)** 文件，检查两个词的位置是否相邻。
    *   如果需要高亮或评分，可能需读取 **.pay (Payloads)** 文件（存储偏移量和权重）。
*   **结果**：此时，我们拿到了匹配的 **DocID List**。

### Step 4: 获取文档原始内容 (.fdx -> .fdt) [关键缺失补全]
搜索完成了，但用户要看的是 JSON。ES 必须拿着 DocID 去“回表”。
*   **结构**：**行式存储 (Stored Fields)**。
*   **跳转 A (.fdx)**：读取 **Field Index (.fdx)**。这是一个轻量级数组，将 `DocID` 映射为 `.fdt` 文件中的数据块偏移量。
*   **跳转 B (.fdt)**：读取 **Field Data (.fdt)**。
    *   **压缩**：.fdt 不是存单条记录，而是将多条文档打包成 **Chunk**，并使用 **LZ4** 或 **Deflate** 压缩。
    *   **代价**：读取 DocID=10，实际上需要解压包含 DocID=10 的整个 Chunk（可能包含 Doc 1-50）。这就是为什么获取 `_source` 是昂贵的，也是为什么深度分页慢的原因之一。
*   **结果**：解压出原始 JSON，返回给用户。

---

## 2. FST (Finite State Transducer)：内存中的奇迹

为了让 Term Index 足够小以至于能装入内存，Lucene 没有使用 B+ 树或 HashMap，而是引入了 FST。

### 2.1 什么是 FST？
FST 是一种有限状态自动机（FSA），它将 `Key -> Value` 的映射关系编码成一个有向无环图（DAG）。
*   **输入**：Term（如 "mop"）。
*   **输出**：Value（如 .tim 文件中的 Block 编号）。

### 2.2 FST 构建过程图解（Mop/Moth/Pop）
假设我们要插入以下词项及其对应的 Value（文件偏移量）：
*   `mop` -> 100
*   `moth` -> 105
*   `pop` -> 200

**构建步骤**：
1.  **插入 "mop"**：创建节点 `Start -> m -> o -> p -> End`。
2.  **插入 "moth"**：
    *   发现前缀 `mo` 已存在，复用节点 `m` 和 `o`。
    *   从 `o` 分叉出 `t -> h`。
    *   **前缀压缩达成**。
3.  **插入 "pop"**：
    *   首字母 `p` 不同，从 Start 新建分支。
    *   **关键点**：后缀 `op` 与 `mop` 的后缀结构完全相同。
    *   在 Lucene 的实现中，如果后续输出一致，FST 会尝试**复用后缀节点**（Suffix Sharing）。`pop` 的 `o -> p` 路径可能指向已存在的节点。

**最终收益**：
*   通过前缀和后缀的双向共享，FST 的空间复杂度主要取决于**数据的相似度**而非数量。
*   实测表明，10亿级词项的索引，FST 仅需 1-2GB 内存。

### 2.3 Arc 的编码艺术
在内存中，FST 被“拍平”为字节数组。节点间的连线（Arc）有多种编码格式：
*   **Linear Scan**：如果一个节点只有 2-3 个出度，直接紧凑排列。查找时顺序扫描。
*   **Direct Addressing**：如果一个节点有 26 个出度（a-z），且分布密集，Lucene 会将其编码为固定长度的**数组**。查找时直接用 `Array[char_code]` 跳转，复杂度 O(1)。

---

## 3. FOR (Frame of Reference)：倒排表的极致压缩

找到 Term 后，我们需要读取对应的文档 ID 列表（Postings List）。这个列表通常是百万级的有序整数，如 `[100, 101, 105, 108...]`。

### 3.1 压缩步骤演练
假设一个 Block 包含以下有序文档 ID：
`Raw IDs: [73, 300, 302, 332, 343, 372 ...]`

#### Step 1: Delta Encoding（增量编码）
计算相邻数值的差值。
`Deltas: [73, 227, 2, 30, 11, 29 ...]`
> **效果**：大整数变成了小整数。

#### Step 2: Bit Packing（位压缩）
将 Delta 列表按 128 个数字分为一组（Block）。分析该组内的数值特征。
*   **场景 A**：组内最大 Delta 是 227（二进制 `11100011`，8 bits）。
    *   Lucene 决定：本组所有数字都用 **8 bits** 存储。
    *   存储空间：$128 	imes 8 	ext{ bits} = 128 	ext{ Bytes}$。
    *   如果不压缩（Int32）：$128 	imes 4 	ext{ Bytes} = 512 	ext{ Bytes}$。
    *   **压缩比：4:1**。

*   **场景 B**：组内数字都很小，最大 Delta 只有 3（二进制 `11`，2 bits）。
    *   Lucene 决定：本组所有数字都用 **2 bits** 存储。
    *   存储空间：$128 	imes 2 / 8 = 32 	ext{ Bytes}$。
    *   **压缩比：16:1**。

#### Step 3: PForDelta（异常值处理）
**问题**：如果 128 个数中，127 个都是 1，只有一个数是 1,000,000（需 20 bits）。
*   如果强行用 20 bits 存所有数，空间浪费巨大。
**解法**：
1.  将那个 1,000,000 视为**异常（Exception）**，单独存储在 Block 的末尾。
2.  在原位置填入一个 Escape Code。
3.  剩下的 127 个数依然按 1 bit 极致压缩。

---

## 4. Roaring Bitmaps：过滤器缓存的王者

在执行 `filter` 查询时（如 `status=active`），结果是一个文档 ID 集合。ES 使用 Node Query Cache 缓存该结果。缓存结构必须兼顾**空间**（内存少）与**时间**（位运算快）。

### 4.1 传统方案的困境
*   **Int Array**：`[1, 100, 10000]`。省空间，但合并（AND/OR）慢，需 O(N) 遍历。
*   **BitSet**：`[0, 1, 0, ...]`。合并极快（CPU 位指令），但稀疏时极浪费空间（1 亿 ID 需 12MB，哪怕只存了 1 个 ID）。

### 4.2 Roaring Bitmap 的分层设计
Roaring Bitmap 将 32位 Integer 拆分为 **高16位 (Chunk Key)** 和 **低16位 (Container Value)**。

*   **Key**：0 ~ 65535。作为索引，指向对应的 Container。
*   **Container**：存储低 16 位的数据。根据数据密度，**动态切换**三种容器：

#### 4.2.1 Array Container (稀疏)
*   **结构**：排序的 `short[]` 数组。
*   **阈值**：**4096**。
    *   **计算逻辑**：Bitmap Container 固定占用 $65536 / 8 = 8192$ Bytes。
    *   Short 类型占用 2 Bytes。
    *   当文档数 $N < 4096$ 时，$N 	imes 2 < 8192$。此时存数组更划算。

#### 4.2.2 Bitmap Container (稠密)
*   **结构**：`long[1024]`（共 64KB bits）。
*   **场景**：当 Container 内文档数超过 4096 时，自动转换为 Bitmap。
*   **优势**：无论存多少数，大小恒定 8KB。且支持 SIMD 位运算加速。

#### 4.2.3 Run Container (连续)
*   **结构**：RLE（Run Length Encoding）。
*   **示例**：ID 序列 `10, 11, 12, ... 1000`。
*   **存储**：`Run(10, 990)`。仅需 4 Bytes 即可存储 1000 个连续 ID。

---

## 5. Doc Values：列式存储 (Columnar Storage)

FST 和倒排索引解决了“搜索”问题，但在“排序”和“聚合”时，我们需要根据 DocID 快速拿到 Value。倒排索引对此无能为力（随机 IO 爆炸）。

### 5.1 物理结构 (.dvd)
Doc Values 是**完全平铺**的数组。
*   `DocID=0 -> Value=100`
*   `DocID=1 -> Value=200`
*   ...
数据在磁盘上连续存储，这意味着 OS 可以利用 **Page Cache** 进行预读（Read-Ahead），极大提升顺序扫描性能。

### 5.2 GCD Compression（最大公约数压缩）
这是 Doc Values 针对数值类型的杀手锏。
*   **原始数据**：`[1000, 2000, 3000, 5000]`（单位：毫秒）。
*   **计算 GCD**：1000。
*   **存储**：`[1, 2, 3, 5]`。
*   **效果**：数值从 5000（需 13 bits）降为 5（需 3 bits）。

---

## 6. 正向索引：行式存储 (Stored Fields)

除了倒排索引和列式存储，ES 还需要存储文档的原始 JSON (`_source`)，以便在搜索结果中返回。这部分称为 **Stored Fields**，由两个核心文件组成：

### 6.1 索引文件 (.fdx)
*   **作用**：建立 `DocID -> Data Offset` 的映射。
*   **结构**：简单的数组。给定 DocID，直接查表得到该文档在 .fdt 文件中的起始位置。

### 6.2 数据文件 (.fdt)
*   **作用**：存储实际的 JSON 二进制数据。
*   **Chunk 压缩机制**：
    *   为了提高压缩率，Lucene 不会单独压缩每一条文档，而是将 **16KB** 的文档数据（或至少 128 篇文档）打包成一个 **Chunk**。
    *   **算法**：默认使用 **LZ4**（追求解压速度），也可配置为 **Deflate**（追求压缩率，类似 GZIP）。
*   **读取代价**：
    *   这是一个“重”操作。当你请求 DocID=10 的 `_source` 时，系统必须将包含 DocID=10 的整个 Chunk（可能包含 DocID 1~50）全部读取并解压，然后在内存中提取出 DocID=10 的部分。
    *   这就是为什么在聚合或排序时，强烈建议使用 **Doc Values**（列存，直接读数值），而不要去访问 `_source`。

---

## 7. 核心文件扩展名全景图 (Cheat Sheet)

| 扩展名 | 文件名 | 核心数据结构 | 驻留内存 | 作用 |
| :--- | :--- | :--- | :--- | :--- |
| **.tip** | Term Index | **FST** | **Heap/Off-heap** | 快速定位词典块，倒排索引的入口 |
| **.tim** | Term Dictionary | BlockTree | Disk | 存储 Term 文本和元数据 |
| **.doc** | Postings | **FOR** | Disk | 存储 DocID 列表 |
| **.pos** | Positions | VInt | Disk | 存储词项位置（用于短语搜索） |
| **.pay** | Payloads | VInt | Disk | 存储权重、偏移量（用于高亮） |
| **.dvd** | Doc Values | **GCD/Table/Sparse** | **OS Cache (mmap)** | 列式存储，用于排序/聚合 |
| **.fdx** | Field Index | Array | Heap/Disk | 定位 .fdt 中的 Chunk |
| **.fdt** | Field Data | **LZ4 Block** | Disk | 存储原始 _source JSON |
| **.dim** | BKD Data | **Block K-D Tree** | Disk | 数值与地理空间数据 |