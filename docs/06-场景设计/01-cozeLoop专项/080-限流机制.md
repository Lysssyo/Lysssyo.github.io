# CozeLoop 限流与流控机制全解析

CozeLoop 构建了一套完整的限流与流控体系。前两层侧重于控制**并发量 (Capacity)**，后两层侧重于控制**速率 (Velocity)**。

## 核心策略概览

| 层级        | 限流目标    | 算法模型      | 核心维度               | 存储/工具             |
| :-------- | :------ | :-------- | :----------------- | :---------------- |
| **API 层** | 准入控制    | 分布式信号量    | Space + Experiment | MySQL (Quota 表)   |
| **调度层**   | 任务分发流控  | 闭环反馈/滑动窗口 | Experiment + Item  | MySQL (Status 状态) |
| **评估层**   | 服务自我保护  | **GCRA**  | Space / Evaluator  | Redis + Lua       |
| **LLM 层** | 上游供应商保护 | **GCRA**  | Model + Scenario   | Redis + Lua       |

---

## 1. API 层 (准入控制 - Admission Control)

*   **空间级实验并发限制**: 通过 `QuotaService` 限制同一个空间内允许同时运行的“实验”总数（默认 10 个）。
*   **清理机制 (Lazy Cleanup)**: 采用“延迟剔除”策略，在每次检查配额时自动清理长时间无响应（超过 ZombieInterval）的“僵尸实验”，确保并发名额不被虚假占用。
*   **用户权益校验**: `CheckBenefit` 在实验启动前校验用户余额或额度，实现成本侧的硬准入。

---

## 2. 调度层 (流控 - Flow Control)

*   **实验内任务并发限制**: 调度器在 `ScanEvalItems` 阶段不采取单纯的时间窗口，而是采用**基于状态反馈的滑动窗口**。
*   **核心逻辑**: 
    1. 首先扫描数据库中处于 `Processing` 的子任务数。
    2. 计算空余位：`submitCnt = 限流量 (ItemConcurNum) - 执行中的数量`。
    3. 仅按 `submitCnt` 的缺口从 `Queueing` 队列捞取新任务下发给 Worker。

```go
func (e *exptBaseExec) ScanEvalItems(ctx context.Context, event *entity.ExptScheduleEvent, expt *entity.Experiment) (toSubmit, incomplete, complete []*entity.ExptEvalItem, err error) {  
    // 1. 扫描执行中的任务，用于计算当前并发
    incomplete, err = e.ScanRunLogEvalItems(ctx, event, expt, &entity.ExptItemRunLogFilter{  
       Status: []entity.ItemRunState{entity.ItemRunState_Processing},  
    }, 0)  
    if err != nil {  
       return nil, nil, nil, err  
    }  
  
    // 2. 根据缺口计算本轮允许下发的数量 (submitCnt)
    if submitCnt := e.getItemConcurNum(ctx, expt) - len(incomplete); submitCnt > 0 {  
       toSubmit, err = e.ScanRunLogEvalItems(ctx, event, expt, &entity.ExptItemRunLogFilter{Status: []entity.ItemRunState{entity.ItemRunState_Queueing}}, int64(submitCnt))  
       if err != nil {  
          return nil, nil, nil, err  
       }  
    }  
  
    // 3. 扫描已完成待收割的任务
    complete, err = e.ScanRunLogEvalItems(ctx, event, expt, &entity.ExptItemRunLogFilter{  
       ResultState: gptr.Of(entity.ExptItemResultStateLogged),  
    }, 0)  
    if err != nil {  
       return nil, nil, nil, err  
    }  
  
    return toSubmit, incomplete, complete, nil  
}
```

*   **作用**: 这是一种天然的**背压 (Backpressure)** 机制。如果后端 Worker 消费变慢，`Processing` 堆积，调度器会自动减速甚至停止分发，防止 MQ 溢出和数据库过载。

---

## 3. 评估层 (服务保护 - Service Protection)

采用双道防线，底层基于 **Redis GCRA 算法**（分布式平滑限流）。

*   **第一道防线：Space 级限流 (租户隔离)**
    *   **阈值**: 默认 **1000 QPS (Burst 1000)**。
    *   **意图**: 确保多租户间的公平性，防止某个空间的异常高频请求拖垮全局评估服务。
*   **第二道防线：Evaluator 级限流 (资源保护)**
    *   **动态性**: 限流阈值绑定在每个 Evaluator 的元数据中。
    *   **差异化**: 允许为昂贵的评估器（如 GPT-4 评分）设置低速率，为廉价评估器（如正则匹配）设置高速率。

```go
// RunEvaluator 核心逻辑 (evaluator_impl.go)
func (e *EvaluatorServiceImpl) RunEvaluator(ctx context.Context, request *entity.RunEvaluatorRequest) (*entity.EvaluatorRecord, error) {
    // ... 
    // 第一道防线：Space 级限流
    if allow := e.limiter.AllowInvoke(ctx, request.SpaceID); !allow {
        return nil, errorx.NewByCode(errno.EvaluatorQPSLimitCode, errorx.WithExtraMsg("space-level throttled"))
    }

    // 第二道防线：Evaluator 级限流 (当前主要用于 CustomRPC 类型)
    if allow := e.plainRateLimiter.AllowInvokeWithKeyLimit(ctx, fmt.Sprintf("run_evaluator:%v", evaluatorDO.ID), evaluatorDO.GetRateLimit()); !allow {
        return nil, errorx.NewByCode(errno.EvaluatorQPSLimitCode, errorx.WithExtraMsg("evaluator-level throttled"))
    }
    // ...
}
```

> [!TIP] **技术点：为什么选择 GCRA？**
> [GCRA 算法 (Generic Cell Rate Algorithm)](../050-限流算法.md#3.%20GCRA%20算法%20(Generic%20Cell%20Rate%20Algorithm))

---

## 4. 大模型运行时层 (上游保护 - Upstream Protection)

这是系统中最严格的一层，直接对应供应商（如 OpenAI, Ark）的 API 红线。

*   **双维度控制**:
    *   **QPM (Queries Per Minute)**: 限制调用频率。
    *   **TPM (Tokens Per Minute)**: 限制 Token 吞吐量。
*   **场景化隔离 (Scenario)**: 针对同一模型，区分 `Evaluator` (后台任务) 和 `PromptDebug` (用户调试)，确保跑批任务不挤占在线调试带宽。
*   **TPM 悲观预扣策略**:
    *   **核心逻辑**: 每次请求前，按配置的 **`MaxTokens`** 预先扣除额度。

```go
// tpm 限流逻辑 (runtime.go)
if tpm >= 0 {
    tpmKey := fmt.Sprintf("%s:%d:%s", "tpm", model.ID, *scenario)
    // 悲观预扣：按可能产生的最大 Token 数进行占位
    result, err := r.rateLimiter.AllowN(ctx, tpmKey, int(req.GetModelConfig().GetMaxTokens()), ...)
    if err == nil && result != nil && !result.Allowed {
        return errorx.NewByCode(llm_errorx.ModelTPMLimitCode)
    }
}
```

*   **权衡**: 这种策略以牺牲部分并发吞吐量为代价，换取了**绝对的安全性**，确保永远不会因为模型幻觉产生超长输出而导致供应商 429 报错。