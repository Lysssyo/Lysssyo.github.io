# 数据集版本控制

> [!TIP] 目标
> 用“版本区间（MVCC 风格）”在同一张主表里同时支持：草稿实时编辑、历史版本回溯、零拷贝发布。

---

## 1. 核心数据模型：版本区间模型（Version Interval / MVCC）

在 `dataset_item` 表中，**每一行代表一个 Item 在某段版本区间内的“有效形态”**。

### 1.1 关键字段

- `add_vn`（Added Version Number）
    - 含义：该行数据“出生”的版本号。
    - 记录时机：数据首次创建，或因修改而产生新行时。
- `del_vn`（Deleted Version Number）
    - 含义：该行数据“失效”的版本号。
    - 特殊值：`MaxVersionNum`（通常为 Int64 最大值）。当 `del_vn = MaxVersionNum` 时，表示该行目前仍然“活着”，属于当前草稿。

### 1.2 存活判定（左闭右开）

一行数据在特定版本 $V$ 是否有效，满足：

$$ \text{Active in } V \iff add\_vn \le V < del\_vn $$

理解：**在 $V$（含）之前出生，并且在** $V$ **之后才死亡**。

---

## 2. 草稿与正式版本

系统将数据集Item状态分成两个逻辑空间：

### 2.1 草稿（Draft）

- 定义：当前正在编辑、尚未封存的状态。
- 存储特征：
    - `dataset_item` 表中 **所有 `del_vn = MaxVersionNum` 的记录**，共同构成当前草稿。
    - 对于`add_vn` ，`dataset.NextVersionNum` 决定下一批新写入数据的 `add_vn`。例如，新建数据集后，对应数据集的 `NextVersionNum = 1`，发布第一个版本前写入的 item，其 `add_vn` 均为 1。

### 2.2 正式版本（Released Version）

- 定义：历史上某个时刻“封存”的数据快照视图。
- 生成方式：**零拷贝发布**
    - 发布时不移动 `dataset_item` 的数据，只是把 `dataset.NextVersionNum` 向前推进
    - 推进的瞬间，**满足 `add_vn ≤ 10 且 del_vn > 10` 的记录**自动成为 “v10 的法定成员”。
- 不可变性：版本一旦发布，该版本所对应区间内的记录在逻辑上不允许被“直接修改”。后续变更通过写时复制完成。

### 2.3 为什么选择该模型

- **查询高性能**：查询任意历史版本仅需一次区间过滤，无需 Undo Log 重放。
- **发版零延迟**：发布操作仅更新元数据，与数据量大小无关。
- **结构简单**：依赖标准关系型数据库索引，不维护复杂链表或指针结构。

---

## 3. 写入流程

所有写操作都发生在一个隐式上下文：**当前草稿版本号**。

- 即，所有Item的写入操作会记当前 `add_vn = dataset.NetVersionNum` ，并且，草稿视图下“活数据”统一满足：`del_vn = MaxVersionNum`

### 3.1 新增（Create）—— 幂等插入（Idempotent Upsert）

- 场景：用户上传一条新数据（Item A）。
- 操作（`MCreateItems`）：
    1. 设置 `add_vn = NetVersionNum`，`del_vn = MaxVersionNum`。
    2. 向 `dataset_item` 插入记录。
    3. 幂等与冲突处理：
        - 唯一索引：`(dataset_id, add_vn, item_key)`。
        - 使用 `INSERT ... ON DUPLICATE KEY UPDATE`。
        - 逻辑：若同一草稿版本内 `item_key` 已存在（常见于重试），则更新已有记录内容而非报错。

<aside> ⚠️

**注意**：新增前如果在内存里预生成了 `item_id`，但最终触发了 `ON DUPLICATE KEY UPDATE`，数据库中的主键可能与内存中不同，需要进行“主键回填”。具体策略参考：[用 RowsAffected 精确推算 Insert 数：以及批量 Upsert 主键回填的写后读策略](https://www.notion.so/RowsAffected-Insert-Upsert-2e02f0e22908800daa3fd5f1ac42a9c3?pvs=21)

</aside>

### 3.2 修改（Update）—— 根据版本属性自动分叉

业务上的“修改一条数据”，底层分为两种截然不同的行为：

**A. 原地更新（In-Place Update）**

- 触发条件：待修改数据 `add_vn == NetVersionNum`。
- 含义：该数据是当前草稿中新创建的，尚未发布过。
- 操作：直接执行 SQL `UPDATE` 修改内容。
- 原因：无需保留更早历史，因为它只是“草稿中的草稿”。

**B. 写时复制（Copy-On-Write / Archive & Create）**

- 触发条件：待修改数据 `add_vn < NetVersionNum`。
- 含义：该数据来自历史版本（例如 v1 创建，现在在 v2 草稿里改）。
- 目标：**草稿看到新值，同时 v1 仍能查到旧值**。
- 操作：在一个事务里两步完成：
    1. Archive（归档旧行）：将旧行 `del_vn` 从 `MaxVersionNum` 更新为 `NetVersionNum`。（在`NetVersionNum` 这个版本里死掉了）
    2. Create（插入新行）：插入新行 `add_vn = NetVersionNum`，`del_vn = MaxVersionNum`，`item_id` 保持不变，但内容为新值。

```go
-- 初始状态：数据库里只有一行，跨度很大
+---------+-----------+--------+--------+
| item_id | data      | add_vn | del_vn |
+---------+-----------+--------+--------+
|  1001   | "Old Val" |   5    |  Max   | <-- 在v5创建，一直活到现在
+---------+-----------+--------+--------+

      ⬇️ 触发修改 (Update item_id=1001) ⬇️
      ⬇️ 判断：add_vn(5) < Current Draft(10)，触发CoW ⬇️

-- 修改后状态：分裂成两行，一个归档，一个新生
+---------+-----------+--------+--------+-----------------------+
| item_id | data      | add_vn | del_vn | 说明                  |
+---------+-----------+--------+--------+-----------------------+
|  1001   | "Old Val" |   5    | **10** | [归档旧行] 在v10这一刻终结 |
|  1001   | "New Val" | **10** |  Max   | [插入新行] v10里的新草稿  |
+---------+-----------+--------+--------+-----------------------+
```

### 3.3 删除（Delete）—— 逻辑删除（归档但不新建）

- 场景：用户删除 Item B。
- 操作（`ArchiveItems`）：将目标记录的 `del_vn` 更新为 `VN_next`。
- 结果：
    - 草稿视角：由于草稿查询 `del_vn = MaxVersionNum`，该条数据“消失”。
    - 历史视角：查询旧版本 $V < VN_next$ 时，仍满足 `del_vn > V`，旧版本可见。

---

## 4. 版本发布流程（Release Flow）

发布的本质是：**零拷贝（Zero-Copy）+ 元数据分界**。

**4.1 全局互斥锁（Write Barrier）**

- 动作：获取 Redis 分布式写锁。
- 效果：阻塞所有新的写入（WriteItem）与 Schema 变更（UpdateSchema），确保发布瞬间一致性。

> [!TIP] 
> 参考[040-语义级分布式读写锁](040-语义级分布式读写锁.md)

**4.2 推进版本号（Bump Version）—— 原子事务**

在一个原子数据库事务中：

- 插入版本记录：在 `dataset_version` 表插入一条新记录，记录当前版本号 $V_{curr}$，并将版本状态置为“未启动/未完成”。
- 锁定 Schema：将当前 Schema 标记为 **Immutable**。
    - 若草稿需要修改 schema：发现不可变后必须 Fork 新 schema，并更新 `dataset.schema_id` 指向新 schema。
- 推进指针：将 `dataset.NextVersionNum` 从 $V_{curr}$ 更新为 $V_{next}$。
    - 关键影响：此刻之后新写入数据将打上 $V_{next}$，而此前数据自然归入 $V_{curr}$ 的历史区间。

**4.3 异步快照（Async Snapshot）**

发布后为了加速未来历史查询，启动异步“搬运工”任务，将该版本数据搬运到快照表。

4.3.1 任务触发

- 事务提交后发送 `DatasetSnapshotJob` 消息到 RocketMQ。
- Consumer 收到消息后执行后台任务。

4.3.2 搬运过程（Worker）

- 数据源：从主表筛选版本 $V$ 的有效数据：
    - `WHERE add_vn <= V AND del_vn > V`
- 分批处理：使用 Cursor 分页，每批读取 50 条写入快照表。
- 断点续传：每写入一批，更新 `dataset_version.snapshot_progress`。
- 容灾：Consumer 崩溃时 MQ 重试，新 Consumer 读取 Cursor 接续执行。

4.3.3 任务终态

- 更新 `dataset_version` 状态为 `Completed`。
- 统计并回填该版本 `ItemCount`（数据总数）作为永久缓存。

---

## 5. 读取路径

读取分为草稿读取与历史读取，并在历史读取中做热/冷降级。

### 5.1 浏览草稿（Draft Access）

- 路由：始终访问 `dataset_item`（主表）。
- 核心条件：`WHERE dataset_id = ? AND del_vn = MaxVersionNum`
- 性能优化：
    - 复合索引：`(dataset_id, del_vn, item_id)`。
    - 实时计数：数据总数用 Redis 计数器维护，避免 `SELECT COUNT(*)`。

### 5.2 浏览历史（History Access）：热/冷降级路由

**热路径：访问快照表（Optimized Path）**

- 触发条件：`DatasetVersion.SnapshotStatus == 'Completed'`。
- 路由：访问 `dataset_item_snapshot`（快照表）。
- 优势：
    - 按 `(version_id, item_id)` 更紧凑存储。
    - 不需要每次计算 `add_vn/del_vn` 区间，性能最优。

**冷路径：回源主表（Fallback Path）**

- 触发条件：快照任务未完成或失败。
- 路由：回源 `dataset_item`（主表）。
- 核心条件（MVCC 区间）：
    1. `WHERE dataset_id = ?`
    2. `AND add_vn <= target_vn`
    3. `AND del_vn > target_vn`
- 意义：即便快照还没搬完，也能准确回溯历史。

### 5.3 元数据与 Schema 绑定（Schema Binding）

无论读草稿还是历史，都需要强制执行“数据清洗（Sanitization）”：

- 草稿：绑定 `dataset.schema_id`（最新结构）。
- 历史：绑定 `dataset_version.schema_id`（发布时结构）。
- 清洗逻辑：根据绑定 Schema 做格式化、默认值填充与字段脱敏。

### 5.4 数据总数（Total Count）策略

- 历史版本：发布后一次性统计并写入 `dataset_version.item_count`，并配合 Redis 永久缓存，查询时 O(1) 返回。
- 草稿版本：
    - 先从 Redis 读取快速计数（可能存在轻微偏差）。
    - 执行数据库分页读取。
    - 若分页发现 `seen >= total`，以分页结果为准（纠偏），避免前端出现“总数比实际条目少”。