---
date created: 2026-01-16 15:39:20
date modified: 2026-01-19 19:21:23
---
# CozeLoop 实验调度机制深入解析

本文档详细解析了 CozeLoop 实验平台的核心调度机制，涵盖了从 API 提交、调度器初始化、循环调度、Worker 执行到最终归档的全生命周期流程，并深入探讨了数据库架构设计与状态流转。

---

## 1. 核心架构与设计理念

CozeLoop 的实验调度系统旨在处理高并发、长耗时的模型评估任务。其架构设计遵循以下三大核心理念：

### 1.1 双层存储架构 (Dual-Layer Storage)
为了兼顾“用户视角的最新状态”与“系统视角的运行历史”，系统采用了双层存储模型：
*   **主表 (ItemResult/TurnResult)**: **快照层**。面向前端 UI 查询，始终只保存该 Item **当前最新** 的一次运行结果。采用 `UPSERT` (覆盖写) 策略。
*   **流水表 (RunLog)**: **调度层**。面向系统调度与回溯，完整记录该 Item 的每一次运行历史（包括重试、失败记录）。采用 `INSERT` (追加写) 策略，通过 `ExptRunID` 实现运行批次的严格隔离。

### 1.2 状态机驱动调度 (State-Driven Scheduling)
系统摒弃了强依赖消息队列确认的机制，转而采用**基于数据库状态**的异步闭环：
*   **Worker** 不直接与调度器通信，仅通过修改流水表的 `ResultState` 为 `Logged` 来“交卷”。
*   **Scheduler** 通过周期性扫描数据库状态来感知任务完成，并触发后续的主表同步与归档。
*   这种设计实现了 Worker 与 Scheduler 的**完全解耦**，即使调度器重启，也能从数据库恢复进度，天然具备**断点续传**能力。

### 1.3 读写分离与最终一致性
*   **OLTP (MySQL)**: 负责高频的状态流转和任务分发，保证调度逻辑的事务性。
*   **OLAP (ClickHouse)**: 负责复杂的多维查询与报表展示。
*   **同步策略**: 采用“初始化占坑 (`Queueing`) + 终态增量更新”的策略，确保用户在任务提交瞬间即可看到列表，随后异步刷新结果，达成了用户体验与系统性能的平衡。


## 2. API 提交阶段

当用户点击“开始实验”或“重试”时，API 层负责校验并触发流程。

1.  **`CreateExpt` (Submit 模式特有)**:
    *   **校验**: 敏感词、余额、数据集有效性、Schema 匹配。
    *   **落库**: 插入 `experiment` (Pending)，关联评估器，预分配 ClickHouse 列映射。

2.  **`RunExperiment`**:
    *   **生成 ID**: 为本次运行生成唯一的 `RunID`。
    *   **抢占分布式锁 (`manager.LogRun`)**:
        *   尝试获取 Redis 锁 `expt_mutex_lock:{ExptID}`。
        *   **关键点**: 如果抢锁失败，直接报错 `ExperimentRunningExistedCode`。这防止了对同一个实验的并发启动操作。
    *   **记录运行日志**: 在 `expt_run_log` 表插入一条记录 (Status: Pending)。
    *   **发送消息**: 向 MQ 发送 `ExptScheduleEvent` {ExptID, RunID, Mode}。

> [!TIP]
>  点击“开始实验”时，实际上是调用的`submitExp`，`submitExp`内部先后调用`CreateExpt`，`RunExperiment`

## 3. 调度器机制详解 (Scheduler Mechanism)

调度器采用了 **责任链 (Chain of Responsibility)** 与 **策略 (Strategy)** 相结合的设计模式，既保证了核心流程的稳定性，又支持了多种运行模式的灵活扩展。

### 3.1 核心架构 (Architecture)
#### A. 整体流程（责任链模式）
`ExptSchedulerImpl` 是调度的总入口，其执行链路通过中间件层层包裹：

1.  **`HandleEventErr` (异常护盾)**:
    *   **Recover**: 捕获 Panic，防止单个实验调度崩溃影响整个 Consumer 进程。
2.  **`HandleEventCheck` (前置校验)**:
    *   **Status Check**: 检查实验是否已处于终态 (`Success/Fail`)，若是则直接跳过，避免无效调度。
3.  **`HandleEventLock` (分布式锁)**:
    *   **Mutex**: 抢占 `expt_mutex_lock:{ExptID}`。确保同一时刻，一个实验只有一个调度器实例在运行，防止并发冲突。
4.  **`HandleEventExec` (核心执行)**:
    *   根据策略模式选择具体的执行器 (`ExptSubmitExec`, `ExptFailRetryExec` 等)。
    *   依次执行 `ExptStart` (初始化) 和 `Schedule` (循环调度)。

#### B. 核心方法 (Schedule Loop)
在 `HandleEventExec` 内部，调度逻辑被封装在 `Schedule` 方法中，它是一个 **基于时间片的无限循环**：

```go
for {
    // 1. 扫描与清理 (Scan)
    toSubmits, incomplete, complete = ScanEvalItems(...)
    
    // 2. 归档收割 (Archive)
    recordEvalItemRunLogs(complete)
    
    // 3. 任务分发 (Dispatch)
    handleToSubmits(toSubmits)
    
    // 4. 退出条件检查
    if len(toSubmits) == 0 && len(incomplete) == 0 {
        ExptEnd() // 终结
        break
    }
    
    // 5. 动态休眠 (Sleep)
    // 根据本轮是否有任务处理，动态决定休眠时间 (有任务不睡，无任务睡 1s)
}
```

### 3.2 调度器启动阶段 (Start Phase)

调度器收到消息后，首先执行初始化逻辑。

*   **入口**: `ExptSubmitExec.ExptStart` (Submit 模式) 或 `ExptFailRetryExec.ExptStart` (Retry 模式)。
*   **Submit 模式初始化**:
    1.  **拉取数据**: 分页调用 `evaluationSetItemService.ListEvaluationSetItems` 拉取数据集。
    2.  **构建对象**: 为每个 Item 创建 `ExptItemResult` 和 `ExptTurnResult` 对象，状态设为 `Queueing`。
    3.  **批量落库 (`BatchCreateNX`)**:
        *   使用 `INSERT IGNORE` 语义批量写入主表 (`expt_item_result`, `expt_turn_result`)，状态为`Queueing`
        *   同时批量写入流水表 (`expt_item_result_run_log`)，状态为 `Queueing`。
    4.  **ClickHouse 全量同步**:
        *   调用 `UpsertExptTurnResultFilter(..., nil)`。
        *   将所有 `Queueing` 状态的记录全量同步到 ClickHouse，用于“占坑”（确保前端显示的总数正确）。
    5.  **更新统计**: 初始化 `expt_stats` 的 `PendingItemCnt`。

### 3.3 循环调度阶段 (Scheduler Loop)

初始化完成后，进入 `ScanEvalItems` -> `recordEvalItemRunLogs` (**Archive** )  -> `handleToSubmits` (**Dispatch**) 的无限循环，直到任务全部完成。

#### A. 扫描任务 (`ScanEvalItems`)
调度器扫描 **`expt_item_result_run_log`** 表，根据 `ExptRunID` 过滤出三类任务：

1.  **`incomplete` (State=Processing)**: 正在运行的任务。用于计算当前并发数。
    *   *僵尸检测 `handleZombies`*: 如果 `UpdatedAt` 超时，视为僵尸任务，标记为 Fail。
2.  **`toSubmit` (State=Queueing)**: 待分发的任务。
    *   *流控*: `submit_count = max_concurrency - len(incomplete)`。
3.  **`complete` (ResultState=Logged)**: Worker 刚跑完的任务。
    *   这是 Worker 通过回调写入流水表后的中间状态，等待调度器收割。

> [!IMPORTANT] 一次扫多少数据呢？
> 在同一个 RunID 内，它也不是一把梭全部扫出来，而是分成了三波：
> 
>   1. 扫描 `Processing`: 为了计算当前还在跑的任务数，判断是否达到了并发上限 (ItemConcurNum)。
>   2. 扫描 `Queueing` (带 Limit): 如果并发还没满，按需扫出 submitCnt 数量的任务准备下发。这是一个滑动窗口，不是全量拉取，有效减轻了 DB 压力。
>   3. 扫描 `Logged`: 专门找那些“Worker 跑完了等收割”的任务进行归档。

> [!IMPORTANT] Question 为什么不是扫描`item_result`这个主表呢？
> 3. RunID 隔离 
> 	* 主表 expt_item_result 每个 Item 只有一行。
> 	* 流水表 expt_item_result_run_log 针对每一次运行（RunID）都会有一组记录。
> 	* 调度器在扫描时强制带上了 `expt_run_id`。这保证了如果针对同一个实验启动了两个Run（虽然目前有锁保护，但在架构设计上是允许的），它们各自的调度器只会扫描属于自己的任务日志，互不干扰。
> 4. 状态机驱动
> 	* 流水表`expt_item_result_run_log`里有一个特有的字段：`result_state`。
> 	* 调度器利用这个字段来识别“收割”时机：当 `result_state` = `Logged` 时，说明 Worker刚写完流水，调度器该去把数据搬运到主表了。
> 	* 主表没有这个中间状态，无法精确控制搬运动作。

#### B. 收割归档 (`recordEvalItemRunLogs`)
针对 `complete` 列表（`Logged` 状态的任务），执行 **归档 (Archive)** 操作：

1.  **防抖**: `Sleep(1s)` 等待主从同步。
2.  **同步主表 (`RecordItemRunLogs`)**:
    *   读取 Worker 写入的 `expt_turn_result_run_log` (包含 Bot 回答、分数)。
    *   **UPSERT** 到主表 `expt_turn_result` (填充 `TargetResultID`, `EvaluatorResultIDs`)。
    *   **UPDATE** 主表 `expt_item_result` 状态为 `Success/Fail`。
3.  **更新流水**: 将 `expt_item_result_run_log` 的 `ResultState` 更新为 **`Resulted`** (处理完毕)。
4.  **ClickHouse 增量同步**: 将带有最终结果和分数的记录同步到 CK。
5.  **结果推送**: (仅在线模式) 通过 Websocket 推送结果。

#### C. 分发任务 (`handleToSubmits`)
针对 `toSubmit` 列表：
1.  **封装事件**: 包装成 `ExptItemEvalEvent`。
2.  **状态更新**:
    *   UPDATE `expt_item_result_run_log` -> `Processing`
    *   UPDATE `expt_item_result` (Item主表) -> `Processing`
    *   UPDATE `expt_turn_result` (Turn 主表) -> `Processing`
    *   UPDATE `expt_stats` (Queueing--, Processing++)
    *   UPDATE `ClickHouse` -> `Processing`
3.  **发送 MQ**: 发给 Worker 节点执行。

### 3.4 调度终结与资源释放 (Termination Phase)

#### A. `ScheduleEnd`: 模式特定的后续钩子
*   **Submit / FailRetry 模式**: **空操作 (No-op)**。这两类模式是单次执行，跑完即停。
*   **Append 模式**: 负责计算下次运行时间并更新 `Cron` 调度器，触发链式运行。
#### B. `ExptEnd`: 通用的物理终结

这是所有实验运行结束后的必经之路，负责“打扫战场”。当调度器检测到 `toSubmit == 0` 且 `incomplete == 0` 时，意味着所有任务均已完结，会走到下面的逻辑

1.  **运行归档 (`CompleteRun`)**:
    *   **统计最终结果**: 再次全量扫描 `expt_turn_result`，计算最终的 `SuccessCnt` 和 `FailCnt`。
    *   **更新日志**: 将 `expt_run_log` 的状态更新为 `Success` 或 `Failed`
    *   **释放分布式锁**: 解除 `expt_mutex_lock:{ExptID}`，允许该实验被再次发起。
2.  **实验结单 (`CompleteExpt`)**:
    *   更新 `experiment` 主表状态：
        *   若所有 Item 均成功 -> `Success`
        *   若存在 Fail Item -> `Success` (注意：业务上部分失败也算实验完成，除非全挂)
    *   记录 `EndTime`。
3.  **资源释放 (Quota Release)**:
    *   调用 `RateLimiter` 归还占用的并发配额。
4.  **后置计算 (Post-Processing)**:
    *   触发 **离线聚合计算 (AggrCalculate)**：异步计算 P90 耗时、平均分、Token 消耗等聚合指标，存入 `expt_result_aggr` 表供报表展示。

---

## 4. Worker 执行机制

Worker 采用 **责任链 (Middleware Chain)** 模式来处理接收到的 `ExptItemEvalEvent` 消息。其处理链路如同洋葱模型，由外向内依次为：

### 4.1 责任链节点 (Middleware Chain)

1.  **`HandleEventErr` (异常护盾)**
    *   **作用**: 最外层的保护罩。
    *   **机制**: 使用 `goroutine.Recover` 捕获所有潜在的 Panic，防止单个畸形任务导致 Worker 进程崩溃。同时负责错误传播，决定是否触发 MQ 重试。

2.  **`HandleEventCheck` (状态守门员)**
    *   **作用**: 避免无效计算。
    *   **逻辑**: 在执行昂贵的模型调用前，先查一下 `expt_run_log`。如果实验已经被用户取消或强制终止，直接返回 `Ack`，不再向下执行，节省 Token 和算力。

3.  **`HandleEventLock` (幂等控制)**
    *   **作用**: 防止同一个 Item 被并发执行。
    *   **逻辑**: 尝试获取分布式锁 `lock:expt:item:{RunID}:{ItemID}`。
        *   若抢锁失败，说明可能有另一个 Worker 正在处理该任务（例如 MQ 网络波动导致的重复投递），当前请求直接放弃。

4.  **`HandleEventExec` (核心业务引擎)**
    *   **作用**: 真正执行评估逻辑。
    *   **流程**:
        1.  **RunEvalTarget**: 调用 Bot/LLM 服务，获取 `Actual Output`。
        2.  **RunEvaluator**: 调用配置的评估器，计算 `Scores`。
        3.  **CompleteItemRun**: 
            *   **INSERT** `expt_turn_result_run_log` (写入详情)。
            *   **UPDATE** `expt_item_result_run_log` (更新状态为 `Logged`)。

---

## 5. 数据库架构与状态机 (DB Schema & State Machine)

### 5.1 数据流转全景图

```text
[ API 层: Create/Run/Retry ]
       |
       +--- (1) INSERT [expt_run_log] (状态: Pending) 
                                                                           
[ 调度器 (Scheduler) - ExptStart 初始化 ]                                  
       |                                                                   
       +--- (2) UPSERT [expt_item_result] & [expt_turn_result] (Status: Queueing)                        
       +--- (3) INSERT [expt_item_result_run_log] (Status: Queueing)                        
       +--- (4) 初始化 [ClickHouse] (Status: Queueing)                      
       |                                                                   
[ 调度器 (Scheduler) - 循环调度周期 ] <-----------------------------------------------------+
       |                                                                                  |
       +--- (5) 任务扫描与清理 (Scan & Cleanup) ---------------------------+                |
       |    |                                                             |                | (NextTick)
       |    +--> [清理僵尸] 检查 Processing 任务是否超时                    |                |
       |    |    - 若超时: 强置为 Fail 并转入 "待收割" 队列                 |                |
       |    |                                                             |                |
       |    +--> [任务分类] 扫描 [expt_item_result_run_log] 并按状态归类:   |                |
       |         - Queueing -> 进入 "待分发" 队列                          |                |
       |         - Logged   -> 进入 "待收割" 队列                          |                |
       |                                                                  |                |
       +--- (6) 任务分发 (Dispatch) -----------------------------------+   |                |
       |    - UPDATE [expt_item_result_run_log] -> Processing          |   |                |
       |    - UPDATE [expt_item_result] & [expt_turn_result] -> Processing |                |
       |    - 更新 [expt_stats] & [ClickHouse] & 发送 MQ                |   |                |
       |                                                               |   |                |
       +--- (7) 收割归档 (Archive) <-----------------------------------+---+                |
       |    - 从 [expt_turn_result_run_log] 同步回答/分数至 [expt_turn_result]              |
       |    - 更新 [expt_stats/ClickHouse] & UPDATE [expt_item_result_run_log] -> Resulted |
       |                                                                                  |
[ 执行器 (Worker) ] <---------------------------------------------------------------------+
       |                                                                    
       +--- (8) 执行模型推理与评估                                            
       +--- (9) INSERT [expt_turn_result_run_log] (模型回答/评估分)                           
       +--- (10) UPDATE [expt_item_result_run_log] (Status: Success/Fail, State: Logged) ---+

[ 完结阶段 (Finalize) ]
       |
       +--- (11) UPDATE [experiment] (最终状态: Success/Failed)
       +--- (12) UPDATE [expt_run_log] (归档统计数据 & 释放锁)
```

### 5.2 核心状态机流转

系统维护了两套平行的状态机：一套用于**内部调度控制** (RunLog)，一套用于**外部结果展示** (Main Table)。

| 阶段 (Phase) | 动作触发者 | 流水表 `expt_item_result_run_log` <br> (驱动调度) | 主表 `expt_item_result` & `expt_turn_result` <br> (驱动 UI) | 关键行为 |
| :--- | :--- | :--- | :--- | :--- |
| **1. Init** | Scheduler | `Status: Queueing` <br> `ResultState: Init` | `Status: Queueing` | 占坑初始化。此时 ClickHouse 也被同步为 Queueing。 |
| **2. Dispatch** | Scheduler | `Status: Processing` <br> `ResultState: Init` | `Status: Processing` | 任务分发进 MQ。UI 变更为“运行中”。 |
| **3. Worker Done** | Worker | `Status: Success/Fail` <br> **`ResultState: Logged`** | `Status: Processing` | **关键中间态**。Worker 已交卷，但主表未更新。调度器扫描到 `Logged` 信号。 |
| **4. Archive** | Scheduler | `Status: Success/Fail` <br> **`ResultState: Resulted`** | **`Status: Success/Fail`** | 收割归档。将 Worker 的回答/分数同步到主表，UI 展示最终结果。 |

> [!TIP] **补充说明**:
> *   `expt_turn_result_run_log` (Turn详情流水): 仅在 **Stage 3 (Worker Done)** 被 Worker 插入一条记录。它是“结果数据”而非“状态数据”，不参与状态机流转。
> *   `ResultState`: 是调度器内部专用的“握手信号”。
>     *   `Init`: 初始/处理中。
>     *   `Logged`: Worker 喊你来搬砖。
>     *   `Resulted`: 搬砖结束，本轮翻篇。

## 6. 限流策略

1. 在同一个 RunID 内，Schedule 也不是一把梭全部扫出来，而是分成了三波：
	1. 扫描 `Processing`: 为了计算当前还在跑的任务数，判断是否达到了并发上限 (ItemConcurNum)。
	2. 扫描 `Queueing` (带 Limit): 如果并发还没满，按需扫出 submitCnt 数量的任务准备下发。这是一个滑动窗口，不是全量拉取，有效减轻了 DB 压力。
	3. 扫描 `Logged`: 专门找那些“Worker 跑完了等收割”的任务进行归档。

## 7. 其他思考

>  为什么要用两个字段来做状态机呢，不能只用`state`吗，如果要表示`worker done`再加多一个状态不就好了。

从理论上讲，我们完全可以在 `Status` 字段里加一个枚举值，比如 `Status_WorkerFinished` 来替代 `ResultState`。但在高并发离线系统中，拆分设计是出于深层考虑：

1. **语义解耦 (业务 vs 系统)**
*   **`Status` (Success/Fail)**: 代表**业务结果**。Worker 跑完那一刻，它已经明确知道自己是成功还是失败了，不应该因为“数据还没同步”就掩盖这个事实。
*   **`ResultState` (Logged/Resulted)**: 代表**数据搬运进度**。这是调度器的内部工作标记。

**如果合二为一的后果**：
假设 Worker 跑失败了，如果只有 `Status`：
*   若标 `Fail`：调度器无法区分这是“刚出炉的 Fail”还是“已归档的旧 Fail”。
*   若标 `Processing_Done`：那就丢失了“我是因为失败而结束”这个业务含义。

**拆分后**：Worker 可以标记 `Status=Fail` + `ResultState=Logged`。调度器一看便知：“哦，是个失败的任务，且我还没收割。”

2. 索引优化与性能
*   调度器最高频的操作是 `Scan`。
*   拆分后，调度器只需要扫描 `ResultState != Resulted` 的活跃记录。
*   归档完的任务变成 `Resulted`，永远退出扫描范围。如果不拆分，随着历史数据堆积，索引过滤条件会变得非常复杂且低效。

3. 支持复杂扩展

	未来如果业务变复杂，比如一个任务分三个阶段（流式输出）：

	- 第1秒：`Status=Processing`, `ResultState=Logged` (输出了一半，喊调度器同步一下)
	- 调度器：同步完，设 `ResultState=Init` (继续等下一波)
	- 第3秒：`Status=Success`, `ResultState=Logged` (全完了)

拆分字段让“业务状态”和“同步信号”可以独立变化，互不锁死。

>  现阶段，如果数据集都是一条一条的，即当前数据集全是单轮对话，那么 `expt_turn_result_run_log` 与 `expt_item_result_run_log` 的拆分是不是没有意义

1. **性能优化：“控制流”与“数据流”分离 (最重要)**

  这是数据库设计中典型的瘦表 (Thin Table) vs 胖表 (Fat Table) 策略。

   * `expt_item_result_run_log` (瘦表 - 控制面)
       * 用途: 供调度器高频 Scan。
       * 特点: 字段少，主要是状态 (Status, ResultState) 和时间戳。
       * 优势: 行记录非常小。InnoDB 的一页 (Page) 能存更多行。调度器在扫描 Processing 或 Queueing 任务时，IO
         效率极高，占用的内存 Buffer Pool 也少。

   * `expt_turn_result_run_log` (胖表 - 数据面)
       * 用途: 存储业务详情。
       * 特点: 包含大量的长文本（Prompt、Response、Debug Log、JSON Blob）。单行数据可能达到 KB 甚至 MB 级别。
       * 优势: 这些数据只有在“归档”那一刻才会被读取一次。

  如果合并的后果：
  
  如果把几十 KB 的回答内容塞到 `item_run_log` 里，虽然调度器 `SELECT` 时可以只查 `Status`
  字段，但数据库引擎在底层加载数据页时，依然会因为行体积过大导致缓存命中率下降，严重的会拖慢整个调度循环的吞吐量。

