# 限流机制

## API 层 (准入控制 - Admission Control)

空间级实验并发限制: 通过 QuotaService 限制同一个空间（Space）内允许同时运行的“实验”总数（例如默认限制 10个）。它会自动清理长时间无响应的“僵尸”实验，确保并发名额不被占用。

## 调度层 (流控 - Flow Control)

实验内任务并发限制：调度器在 ScanEvalItems 阶段采用滑动窗口机制。

调度器不会一口气把所有的子任务都扫出来，发给worker去执行，而是根据滑动窗口，按需扫描。会先把执行中的扫出来，然后再用`限流量 - 执行中的数量 = 待执行的数量`，扫出待执行的任务

 只有当 当前并发数 < ItemConcurNum 时，才会下发新的 Queueing 任务。
 
 作用：防止单个包含数万条数据的巨型实验瞬间产生海量 MQ 消息，从而压垮 Worker 集群。

``` go
func (e *exptBaseExec) ScanEvalItems(ctx context.Context, event *entity.ExptScheduleEvent, expt *entity.Experiment) (toSubmit, incomplete, complete []*entity.ExptEvalItem, err error) {  
    incomplete, err = e.ScanRunLogEvalItems(ctx, event, expt, &entity.ExptItemRunLogFilter{  
       Status: []entity.ItemRunState{entity.ItemRunState_Processing},  
    }, 0)  
    if err != nil {  
       return nil, nil, nil, err  
    }  
  
	// submitCnt = ItemConcurNum(限流量) - 执行中的数量
    if submitCnt := e.getItemConcurNum(ctx, expt) - len(incomplete); submitCnt > 0 {  
       toSubmit, err = e.ScanRunLogEvalItems(ctx, event, expt, &entity.ExptItemRunLogFilter{Status: []entity.ItemRunState{entity.ItemRunState_Queueing}}, int64(submitCnt))  
       if err != nil {  
          return nil, nil, nil, err  
       }  
    }  
  
    complete, err = e.ScanRunLogEvalItems(ctx, event, expt, &entity.ExptItemRunLogFilter{  
       ResultState: gptr.Of(entity.ExptItemResultStateLogged),  
    }, 0)  
    if err != nil {  
       return nil, nil, nil, err  
    }  
  
    return toSubmit, incomplete, complete, nil  
}

```

## 评估层 (服务保护 - Service Protection)

这一层的限流主要发生在 EvaluatorServiceImpl.RunEvaluator方法中

核心目的是防止评估服务被过载调用，采用了两道防线：Space 级限流 和 Evaluator 级限流。

  在 backend/modules/evaluation/domain/service/evaluator_impl.go 的第 359 行左右：

    1 // RunEvaluator evaluator_version 运行
    2 func (e *EvaluatorServiceImpl) RunEvaluator(ctx context.Context, request *entity.RunEvaluatorRequest)
      (*entity.EvaluatorRecord, error) {
    3     // ... (省略前置查询逻辑) ...
    4
    5     // 第一道防线：Space 级限流 (QPS)
    6     if allow := e.limiter.AllowInvoke(ctx, request.SpaceID); !allow {
    7         return nil, errorx.NewByCode(errno.EvaluatorQPSLimitCode, errorx.WithExtraMsg("evaluator throttled due to
      space-level rate limit"))
    8     }
    9
   10     // 第二道防线：Evaluator 级限流 (QPS)
   11     if allow := e.plainRateLimiter.AllowInvokeWithKeyLimit(ctx, fmt.Sprintf("run_evaluator:%v", evaluatorDO.ID),
      evaluatorDO.GetRateLimit()); !allow {
   12         return nil, errorx.NewByCode(errno.EvaluatorQPSLimitCode, errorx.WithExtraMsg("evaluator throttled due to
      evaluator-level rate limit"))
   13     }
   14
   15     // ... (后续执行逻辑) ...
   16 }

  第一道防线：Space 级限流

   * 代码: e.limiter.AllowInvoke(ctx, request.SpaceID)
   * 接口定义: repo.RateLimiter
   * 设计意图: 多租户隔离与公平性。
       * CozeLoop 是一个多租户系统（Space 即租户空间）。
       * 如果没有这一层，一个 Space 发起的高频攻击（或者意外的死循环脚本）可能会耗尽所有 Worker 资源，导致其他 Space
         的任务排队等待。
       * 通过限制每个 Space 的调用频率（例如：每秒最多 100 次调用），保证了系统的租户级隔离。
   * 底层推测: 这里传入的是 int64 类型的 SpaceID，底层很可能是基于 Redis 的计数器或令牌桶，Key 类似于
     limiter:space:{SpaceID}。

  第二道防线：Evaluator 级限流

   * 代码: e.plainRateLimiter.AllowInvokeWithKeyLimit(ctx, fmt.Sprintf("run_evaluator:%v", evaluatorDO.ID),
     evaluatorDO.GetRateLimit())
   * 接口定义: repo.IPlainRateLimiter
   * 动态参数: 注意这里传入了 evaluatorDO.GetRateLimit()。这意味着不同的评估器可以有不同的限流阈值。
   * 设计意图: 保护高昂/稀缺资源的评估器。
       * 评估器的成本差异巨大。
           * 一个简单的正则匹配评估器 (Regex Evaluator) 执行极快，QPS 限制可以很高（如 1000）。
           * 一个基于 GPT-4 的复杂评分器 (Prompt Evaluator) 执行慢且贵，QPS 限制必须很低（如 10）。
       * 这个限流是针对 Evaluator ID 的。即使用户在同一个 Space 下跑了多个实验，只要它们用的是同一个 GPT-4
         评估器，总量就会被限制住。
   * Key 的构造: run_evaluator:{EvaluatorID}。这是一个全局 Key，跨 Space 生效（如果该评估器被共享的话，但在 CozeLoop
     业务中 Evaluator 通常归属 Space，所以主要是限制该 Space 内对特定评估器的并发滥用）。

底层算法：基于 Redis 的 GCRA 算法

## 大模型运行时层 (上游保护 - Upstream Protection)


   * 模型/场景级 QPM (每分钟请求数): 限制每分钟向特定模型发送的请求总数。
   * 模型/场景级 TPM (每分钟 Token 数): 限制每分钟消耗的 Token 总量。
       * 实现: 采用令牌桶算法 (AllowN)。
       * 预扣策略: 根据 MaxTokens 配置进行“预扣预占”，这是一种悲观且安全的策略，防止生成过程中 Token 溢出。



