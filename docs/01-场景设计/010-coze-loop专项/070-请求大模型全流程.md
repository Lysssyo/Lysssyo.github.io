# 请求大模型全流程

## 第一阶段：Evaluation 服务 (发起者)

1. 方法: EvaluatorSourcePromptServiceImpl.chat
    - 输入: EvaluatorVersion (包含 Prompt, 变量, 模型配置), exptSpaceID 等。
    - 动作: 创建 LLMCallParam 结构体，把 Prompt 消息放进去。
    - 调用: p.llmProvider.Call(ctx, llmCallParam)
2. 方法: LLMRPCAdapter.Call (RPC 适配层)
    - 动作:
        - 数据转换: 调用 LLMCallParamConvert -> MessageDO2DTO
        - RPC 发送: l.client.Chat(ctx, req)。通过 Thrift 协议将请求发送给 LLM 服务。

---

## 第二阶段：LLM Runtime 服务 (处理者)

1. 方法: runtimeApp.Chat (服务端入口)
    - 动作:
        - RPC 接收: 收到 Thrift 请求。
        - 数据转换: convertor.MessagesDTO2DO，把 Thrift DTO 转回 LLM 内部 Entity。
        - 校验: manageSrv.GetModelByID (确认模型存在), model.Valid() (确认配置合法), rateLimitAllow (限流检查)。
        - 调用: runtimeSrv.HandleMsgsPreCallModel
        - 调用:`r.runtimeSrv.Generate`
2. 方法: RuntimeImpl.HandleMsgsPreCallModel (多模态预处理)
    - 动作:
        - 遍历消息，发现 MultiModalContent 中的图片 URL。
        - 下载与转码: 请求 MinIO 下载图片 -> 转成 Base64 字符串。
        - 替换: 用 Base64 字符串覆盖原来的 URL。
    - 状态: 此时内存里的消息对象，已经包含了真实的图片数据。
3. 方法: RuntimeImpl.Generate (运行时执行)
    - 动作:
        - buildLLM: 根据 model_config.yaml 里的配置（frame: eino, protocol: ark），创建一个封装了 Ark 组件的 LLM 对象。
        - 调用: llm.Generate(ctx, input, opts...)。

---

## 第三阶段：Eino 框架与底层 SDK (执行者)

1. 方法: eino.LLM.Generate (Eino 适配层)
    - 动作:
        - entity.FromDOMessages: 把 LLM Entity 转成 Eino Schema (再次确认多模态字段没丢)。
        - 调用: l.chatModel.Generate(...)。
2. 方法: ark.ChatModel.Generate (Eino Ark 组件)
    - 动作:
        - Eino 内部调用火山引擎（Ark）的官方 Go SDK。
        - SDK 将请求序列化为 JSON，通过 HTTP POST 发送到 [https://api.ark.cn-beijing.volces.com/](https://api.ark.cn-beijing.volces.com/)...。
        - 请求体: 包含了 Prompt 文本 + 那串长长的 Base64 图片数据。

---

## 第四阶段：云端与响应 (Cloud & Response)

1. 云端: 火山引擎服务器
    - 收到请求，解码 Base64 图片。
    - 运行大模型推理（Inference）。
    - 返回 JSON 结果：{"content": "这张图里有一只可爱的小猫。"}。
2. 回程:
    - Eino 收到 HTTP 响应 -> 转成 Eino Schema。
    - Runtime 收到 Eino 结果 -> 转成 LLM Entity。
    - Chat 方法收到 LLM Entity -> 转成 Thrift DTO -> 返回 RPC 响应。
    - Evaluation 服务收到 RPC 响应 -> 解析结果。

---