```go
const (
	createVersionMaxWait = time.Minute
	writeItemMaxWait     = time.Minute
	updateSchemaMaxWait  = time.Minute
)

func (s *DatasetServiceImpl) withWriteItemBarrier(ctx context.Context, datasetID int64, itemCount int64) (release func(), err error) {
	if err := s.waitNoOp(ctx, datasetID, []entity.DatasetOpType{
		entity.DatasetOpTypeCreateVersion,
		entity.DatasetOpTypeUpdateSchema,
	}, writeItemMaxWait); err != nil {
		return nil, err
	}

	ttl := time.Minute
	return s.withOpBarrier(ctx, datasetID, entity.DatasetOpTypeWriteItem, ttl)
}

func (s *DatasetServiceImpl) withUpdateSchemaBarrier(ctx context.Context, datasetID int64) (release func(), err error) {
	// 与上面类似，省略
}

// 纯粹的 “轮询等待” (Polling/Waiter) 逻辑
func (s *DatasetServiceImpl) waitNoOp(ctx context.Context, datasetID int64, opTypes []entity.DatasetOpType, maxWait time.Duration) error {
	bo := backoff.NewExponentialBackOff()
	bo.MaxElapsedTime = maxWait
	bo.InitialInterval = 50 * time.Millisecond
	bo.MaxInterval = time.Second * 10

	var (
		opM map[entity.DatasetOpType][]*entity.DatasetOperation
		err error
	)

	if err := backoff.Retry(func() error {
		opM, err = s.repo.MGetDatasetOperations(ctx, datasetID, opTypes)
		if err != nil {
			return err // 指定操作类型不为空，返回错误
		}
		if len(opM) == 0 {
			return nil // 返回 nil，表示等待结束，可以继续后续业务
		}
		return errors.Errorf(`%d operations are running`, len(opM))
	}, bo); err != nil {
		s := gslice.Flatten(gmap.Values(opM))
		return errors.WithMessagef(err, "operations=%v", gslice.Map(s, func(op *entity.DatasetOperation) string {
			return op.String()
		}))
	}

	return nil
}

func (s *DatasetServiceImpl) withOpBarrier(ctx context.Context, datasetID int64, opType entity.DatasetOpType, ttl time.Duration) (release func(), err error) {
	op := &entity.DatasetOperation{
		Type: opType,
		TS:   time.Now(),
		TTL:  ttl,
	}

	if err := s.repo.AddDatasetOperation(ctx, datasetID, op); err != nil {
		return func() {}, errors.WithMessage(err, "add dataset operation")
	}

	logs.CtxInfo(ctx, "add dataset operation, dataset_id=%d, op=%v", datasetID, op)
	release = func() {
		if err := s.repo.DelDatasetOperation(ctx, datasetID, opType, op.ID); err != nil {
			logs.CtxWarn(ctx, "del dataset operation failed, op_id=%s, op_type=%s, err=%v", op.ID, opType, err)
		}
	}
	return release, nil
}
```

`withWriteItemBarrier` 是基于 Redis 的“语义级分布式读写锁 / 操作屏障”，允许同一数据集的**高并发写入**，但在**版本发布**或 **Schema 变更**等“结构性操作”发生时，阻断并发写，避免结构变更与写入交错导致的数据不一致。

### 1. 核心作用与业务场景

在 `ArchiveAndCreateItem`（归档旧 Item 并创建新 Item）的上下文中：

- **允许**：多个用户同时对同一个数据集写入 Item（并发 WriteItem）
- **禁止**：写入 Item 的同时发生：
    - `CreateVersion`（版本发布）
    - `UpdateSchema`（Schema 变更）

### 2. 互斥矩阵

|当前操作|需要等待（被阻塞）的操作类型|是否阻塞其他 WriteItem？|
|---|---|---|
|WriteItem|CreateVersion, UpdateSchema|否（支持高并发）|
|CreateVersion|WriteItem, UpdateSchema, CreateVersion|是|
|UpdateSchema|WriteItem, CreateVersion|是|

### 3. 实现原理（3 个阶段）

整体流程：**等待（Check） → 加锁（Acquire） → 解锁（Release）**。

**A. 存储结构（Redis Hash）**

系统用 Redis Hash 存储“当前正在进行的操作”。

- **Key（推测）**：`dataset:{id}:op:{op_type}`
- **Field**：`op_id`（UUID 或唯一标识）
- **Value**：JSON 字符串（包含时间戳与 TTL）

**B. 等待阶段：`waitNoOp`（自旋 + 退避）**

- 调用 `repo.MGetDatasetOperations` 检查当前数据集是否存在互斥操作（例如 `CreateVersion`）。
- **惰性过期清理**：读取时检查记录是否超过 TTL（默认 1 分钟），若过期则顺便删除，避免死锁。
- **重试机制**：若发现互斥操作进行中，使用**指数退避**轮询等待，最长等待 1 分钟。

**C. 加锁阶段：`withOpBarrier`（写入操作记录）**

当确认不存在互斥操作后：

1. 生成 `DatasetOperation`，类型标记为 `WriteItem`。
2. 使用 `HSET` 写入 Redis：

```
HSET dataset:1001:op:WriteItem  "op-uuid-123"  "{\\"type\\":\\"WriteItem\\",\\"ts\\":...}"
```

**关键点**：同一个 `op:WriteItem` Hash 里允许存在多个 field（多个 `op_id`），所以可以实现**多写并发**。

**D. 解锁阶段：`release()`（删除操作记录）**

操作结束后删除对应记录：

```
HDEL dataset:1001:op:WriteItem "op-uuid-123"
```

---

### 4. 为什么这么设计？

1. **高并发吞吐**：
    - 传统 Redis `SETNX` 互斥锁是“全互斥”，写入容易成为瓶颈。
    - 这里允许任意数量 `WriteItem` 并发，最后写入的获胜，只在少数“发布版本 / 修改结构”的场景阻断写入。
2. **降低死锁风险**：
    - 记录带 TTL，读取时自动清理过期数据。
    - 等待有最大超时（1 分钟），不会无限阻塞。

### 5. 深入理解读写锁

在计算机科学中，读写锁主要解决的是“读多写少”场景下的性能问题。它有两种模式：

- 读锁 (Shared Lock / R-Lock，共享锁)：
    - 规则：如果有人加了读锁，其他人也可以加读锁（大家一起读），但不能加写锁（不能改）。
- 写锁 (Exclusive Lock / W-Lock，独占锁)：
    - 规则：如果有人加了写锁，其他人既不能加读锁，也不能加写锁。

在这个项目中，虽然操作名字叫 `WriteItem（写数据）`和`CreateVersion（创建版本）`，但从锁的行为模式来看，它们正好对应了读写锁的两种角色：

**角色 A：WriteItem (对应标准模型中的“读锁”)**

- 行为：允许并发执行。多个用户可以同时调用 ArchiveAndCreateItem 往同一个 Dataset 里写数据。
- 代码体现：waitNoOp 检查的是 CreateVersion 和 UpdateSchema，但不检查 WriteItem。也就是说，如果有其他人在WriteItem，我也可以 WriteItem。
- 为什么叫“读锁”？：在版本管理这个更高维度的视角下，写入数据（Item）只是在当前的草稿区（Draft）增加内容，并没有改变数据集的结构（Schema）或发布状态（Version）。对于“数据集结构/版本状态”这个资源来说，普通的写数据操作并由没有破坏性，大家可以一起做，行为就像“共享锁”。

**角色 B：CreateVersion / UpdateSchema (对应标准模型中的“写锁”)**

- 行为：独占执行。一旦开始创建版本，必须要等所有的 Item 写入停下来；一旦它开始了，新的 Item 写入也进不来。
- 代码体现：
    - withCreateVersionBarrier 会等待 WriteItem。
    - withWriteItemBarrier 会等待 CreateVersion。
- 为什么叫“写锁”？：因为这些操作会改变数据集的全局状态（比如封存当前所有数据生成快照）。这时候必须“清场”，保证数据静止，才能安全操作。这完全符合“独占锁”的特征

### 6. 代码位置索引

- 业务入口：`backend/modules/data/domain/dataset/service/item.go` → `ArchiveAndCreateItem`
- 锁逻辑控制：`backend/modules/data/domain/dataset/service/operation.go` → `withWriteItemBarrier`
- Redis 实现：`backend/modules/data/infra/repo/dataset/redis/operation_dao.go`