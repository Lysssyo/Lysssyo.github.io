---
date created: 2026-01-16 15:39:20
date modified: 2026-01-21 14:51:14
---
# CozeLoop 实验调度机制深入解析

本文档详细解析了 CozeLoop 实验平台的核心调度机制，涵盖了从 API 提交、调度器初始化、循环调度、Worker 执行到最终归档的全生命周期流程，并深入探讨了数据库架构设计与状态流转。

---

## 1. 核心架构与设计理念

CozeLoop 的实验调度系统旨在处理高并发、长耗时的模型评估任务。其架构设计遵循以下三大核心理念：

### 1.1 双层存储架构 (Dual-Layer Storage)
为了兼顾“用户视角的最新状态”与“系统视角的运行历史”，系统采用了双层存储模型：
*   **主表 (ItemResult/TurnResult)**: **快照层**。面向前端 UI 查询，始终只保存该 Item **当前最新** 的一次运行结果。采用 `UPSERT` (覆盖写) 策略。
*   **流水表 (RunLog)**: **调度层**。面向系统调度与回溯，完整记录该 Item 的每一次运行历史（包括重试、失败记录）。采用 `INSERT` (追加写) 策略，通过 `ExptRunID` 实现运行批次的严格隔离。

### 1.2 状态机驱动调度 (State-Driven Scheduling)
系统摒弃了强依赖消息队列确认的机制，转而采用**基于数据库状态**的异步闭环：
*   **Worker** 不直接与调度器通信，仅通过修改流水表的 `ResultState` 为 `Logged` 来“交卷”。
*   **Scheduler** 通过周期性扫描数据库状态来感知任务完成，并触发后续的主表同步与归档。
*   这种设计实现了 Worker 与 Scheduler 的**完全解耦**，即使调度器重启，也能从数据库恢复进度，天然具备**断点续传**能力。

### 1.3 读写分离与最终一致性
*   **OLTP (MySQL)**: 负责高频的状态流转和任务分发，保证调度逻辑的事务性。
*   **OLAP (ClickHouse)**: 负责复杂的多维查询与报表展示。
*   **同步策略**: 采用“初始化占坑 (`Queueing`) + 终态增量更新”的策略，确保用户在任务提交瞬间即可看到列表，随后异步刷新结果，达成了用户体验与系统性能的平衡。


## 2. API 提交阶段

当用户点击“开始实验”或“重试”时，API 层负责校验并触发流程。

1.  **`CreateExpt` (Submit 模式特有)**:
    *   **校验**: 敏感词、余额、数据集有效性、Schema 匹配。
    *   **落库**: 插入 `experiment` (Pending)，关联评估器，预分配 ClickHouse 列映射。

2.  **`RunExperiment`**:
    *   **生成 ID**: 为本次运行生成唯一的 `RunID`。
    *   **抢占分布式锁 (`manager.LogRun`)**:
        *   尝试获取 Redis 锁 `expt_mutex_lock:{ExptID}`。
        *   **关键点**: 如果抢锁失败，直接报错 `ExperimentRunningExistedCode`。这防止了对同一个实验的并发启动操作。
    *   **记录运行日志**: 在 `expt_run_log` 表插入一条记录 (Status: Pending)。
    *   **发送消息**: 向 MQ 发送 `ExptScheduleEvent` {ExptID, RunID, Mode}。

> [!TIP]
>  点击“开始实验”时，实际上是调用的`submitExp`，`submitExp`内部先后调用`CreateExpt`，`RunExperiment`

## 3. 调度器机制详解 (Scheduler Mechanism)

调度器采用了 **责任链 (Chain of Responsibility)** 与 **策略 (Strategy)** 相结合的设计模式，既保证了核心流程的稳定性，又支持了多种运行模式的灵活扩展。

### 3.1 核心架构 (Architecture)
#### A. 整体流程（责任链模式）
`ExptSchedulerImpl` 是调度的总入口，其执行链路通过中间件层层包裹：

1.  **`HandleEventErr` (异常护盾)**:
    *   **Recover**: 捕获 Panic，防止单个实验调度崩溃影响整个 Consumer 进程。
2.  **`HandleEventCheck` (前置校验)**:
    *   **Status Check**: 检查实验是否已处于终态 (`Success/Fail`)，若是则直接跳过，避免无效调度。
3.  **`HandleEventLock` (分布式锁)**:
    *   **Mutex**: 抢占 `expt_mutex_lock:{ExptID}`。确保同一时刻，一个实验只有一个调度器实例在运行，防止并发冲突。
4.  **`HandleEventExec` (核心执行)**:
    *   根据策略模式选择具体的执行器 (`ExptSubmitExec`, `ExptFailRetryExec` 等)。
    *   依次执行 `ExptStart` (初始化) 和 `Schedule` (循环调度)。

#### B. 核心方法 (Schedule Loop)
在 `HandleEventExec` 内部，调度逻辑被封装在 `Schedule` 方法中，它是一个 **基于时间片的无限循环**：

```go
for {
    // 1. 扫描与清理 (Scan)
    toSubmits, incomplete, complete = ScanEvalItems(...)
    
    // 2. 归档收割 (Archive)
    recordEvalItemRunLogs(complete)
    
    // 3. 任务分发 (Dispatch)
    handleToSubmits(toSubmits)
    
    // 4. 退出条件检查
    if len(toSubmits) == 0 && len(incomplete) == 0 {
        ExptEnd() // 终结
        break
    }
    
    // 5. 动态休眠 (Sleep)
    // 根据本轮是否有任务处理，动态决定休眠时间 (有任务不睡，无任务睡 1s)
}
```

### 3.2 调度器启动阶段 (Start Phase)

调度器收到消息后，根据模式（Submit 或 FailRetry）执行不同的初始化逻辑。

#### A. Submit 模式 (`ExptSubmitExec.ExptStart`)

这是“无中生有”的全量启动过程。

1.  **拉取数据**: 分页调用 `evaluationSetItemService.ListEvaluationSetItems` 拉取数据集。
2.  **构建对象**: 为每个 Item 创建 `ExptItemResult` 和 `ExptTurnResult` 对象，状态设为 `Queueing`。
3.  **批量落库 (`BatchCreateNX`)**:
    *   使用 `INSERT IGNORE` 语义批量写入主表 (`expt_item_result`, `expt_turn_result`)，状态为`Queueing`
    *   同时批量写入流水表 (`expt_item_result_run_log`)，状态为 `Queueing`。
4.  **ClickHouse 全量同步**:
    *   调用 `UpsertExptTurnResultFilter(..., nil)`。
    *   将所有 `Queueing` 状态的记录全量同步到 ClickHouse，用于“占坑”（确保前端显示的总数正确）。
5.  **更新统计**: 初始化 `expt_stats` 的 `PendingItemCnt`。

#### B. 失败重跑模式 (`ExptFailRetryExec.ExptStart`)

Retry 模式的核心逻辑是 **“查漏补缺”**。它不从数据集全量拉取，而是基于**主表**的快照，筛选出上次运行失败的任务进行“原地复活”。

1.  **扫描“失败者”**: 分批扫描 `expt_turn_result` 表，筛选出状态为 `Fail`、`Terminated` 或卡在 `Processing/Queueing` 的所有 Turn。
2.  **构建新 RunLog**:
    *   为这些失败的 Item 生成新的 `expt_item_result_run_log`。
    *   **关键**: 状态设为 `Queueing`，但 `ExptRunID` 更新为本次重试的新 RunID。这相当于发了一张新的“准考证”。
3.  **重置主表状态**:
    *   `UPDATE expt_item_result`: Status -> `Queueing`, ExptRunID -> 新 RunID。
    *   `UPDATE expt_turn_result`: Status -> `Queueing`.
    *   **作用**: 让前端 UI 上的红色“失败”图标瞬间变回灰色“排队中”。
4.  **重置统计**:
    *   读取 `expt_stats`，将 `FailCnt` 和 `ProcessingCnt` 清零，并将这些计数加回到 `PendingCnt` 中，重置进度条。
5.  **触发调度**:
    *   最后，将生成的 `expt_item_result_run_log` 批量插入数据库。调度器的 `Scan` 循环随即能扫到这些新任务，开始分发。

> [!NOTE] 断点续传在哪里体现？
> `ExptStart` 只负责把 Item 扔回池子。真正的断点续传（即保留该 Item 中已成功的 Turn 结果，只重跑失败的 Turn）是在 **Worker** 的 `PreEval` 阶段通过“克隆旧结果”实现的，调度器只管 Item 级的重启。

### 3.3 循环调度阶段 (Scheduler Loop)

初始化完成后，进入 `ScanEvalItems` -> `recordEvalItemRunLogs` (**Archive** )  -> `handleToSubmits` (**Dispatch**) 的无限循环，直到任务全部完成。

#### A. 扫描任务 (`ScanEvalItems`)
调度器扫描 **`expt_item_result_run_log`** 表，根据 `ExptRunID` 过滤出三类任务：

1.  **`incomplete` (State=Processing)**: 正在运行的任务。用于计算当前并发数。
    *   *僵尸检测 `handleZombies`*: 如果 `UpdatedAt` 超时，视为僵尸任务，标记为 Fail。后续加入到`complete`列表
2.  **`toSubmit` (State=Queueing)**: 待分发的任务。
    *   *流控*: `submit_count = max_concurrency - len(incomplete)`。
3.  **`complete` (ResultState=Logged)**: Worker 刚跑完的任务。
    *   这是 Worker 通过回调写入流水表后的中间状态，等待调度器收割。

> [!IMPORTANT] 一次扫多少数据呢？
> 在同一个 RunID 内，它也不是一把梭全部扫出来，而是分成了三波：
> 
>   1. 扫描 `Processing`: 为了计算当前还在跑的任务数，判断是否达到了并发上限 (ItemConcurNum)。
>   2. 扫描 `Queueing` (带 Limit): 如果并发还没满，按需扫出 submitCnt 数量的任务准备下发。这是一个滑动窗口，不是全量拉取，有效减轻了 DB 压力。
>   3. 扫描 `Logged`: 专门找那些“Worker 跑完了等收割”的任务进行归档。

> [!IMPORTANT] Question 为什么不是扫描`item_result`这个主表呢？
> 3. RunID 隔离 
> 	* 主表 expt_item_result 每个 Item 只有一行。
> 	* 流水表 expt_item_result_run_log 针对每一次运行（RunID）都会有一组记录。
> 	* 调度器在扫描时强制带上了 `expt_run_id`。这保证了如果针对同一个实验启动了两个Run（虽然目前有锁保护，但在架构设计上是允许的），它们各自的调度器只会扫描属于自己的任务日志，互不干扰。
> 4. 状态机驱动
> 	* 流水表`expt_item_result_run_log`里有一个特有的字段：`result_state`。
> 	* 调度器利用这个字段来识别“收割”时机：当 `result_state` = `Logged` 时，说明 Worker刚写完流水，调度器该去把数据搬运到主表了。
> 	* 主表没有这个中间状态，无法精确控制搬运动作。

#### B. 收割归档 (`recordEvalItemRunLogs`)
针对 `complete` 列表（`Logged` 状态的任务），执行 **归档 (Archive)** 操作。其核心逻辑在于调用 `RecordItemRunLogs` 将数据从“流水层”搬运回“快照层”，涉及以下 5 张表的联动修改：

1.  **防抖**: `Sleep(1s)` 等待数据库主从同步完成，确保能读到 Worker 刚刚写入的 RunLog。
2.  **核心搬运 (`RecordItemRunLogs`)**: 这是一个单 Item 事务操作（逻辑上），确保以下数据一致性：
    *   **`expt_turn_evaluator_result_ref` (插入)**: 将 `expt_turn_result_run_log` 中 `evaluator_results` 字段保存的多个评估器 ID 展开，插入此关联表。
    *   **`expt_turn_result` (更新主表)**: 将流水表中的 `err_msg`、`log_id`、`status` 等核心结果回填到主表。
    *   **`expt_item_result` (更新主表)**: 更新 Item 的最终 `status` (Success/Fail) 以及 `log_id`。
    *   **`expt_item_result_run_log` (更新流水)**: 将 `result_state` 从 `Logged` (待收割) 变更为 **`Resulted`** (已收割)。这是收割流程完成的物理标志，使其退出调度器的扫描窗口。
    *   **`expt_stats` (更新统计)**: 调用 `ArithOperateCount` 原子增减实验全局计数（如：Success +1, Processing -1）。
3.  **ClickHouse 增量同步**: 调用 `UpsertExptTurnResultFilter` 向 CK 同步辅助表插入 ItemID。这会触发 ClickHouse 的数据拉取任务，将 MySQL 中的最新结果同步到 OLAP 层。
4.  **下发信号**: 发送 `ExptTurnResultFilterEvent` 消息，通知下游系统（如报表、监控）数据已准备就绪。
5.  **结果推送**: (仅在线模式) 根据实验配置，通过 Websocket 或 Callback 推送实时结果。

#### C. 分发任务 (`handleToSubmits`)
针对 `toSubmit` 列表：
1.  **封装事件**: 包装成 `ExptItemEvalEvent`。
2.  **状态更新**:
    *   UPDATE `expt_item_result_run_log` -> `Processing`
    *   UPDATE `expt_item_result` (Item主表) -> `Processing`
    *   UPDATE `expt_turn_result` (Turn 主表) -> `Processing`
    *   UPDATE `expt_stats` (Queueing--, Processing++)
    *   UPDATE `ClickHouse` -> `Processing`
3.  **发送 MQ**: 发给 Worker 节点执行。

### 3.4 调度终结与资源释放 (Termination Phase)

#### A. `ScheduleEnd`: 模式特定的后续钩子
*   **Submit / FailRetry 模式**: **空操作 (No-op)**。这两类模式是单次执行，跑完即停。
*   **Append 模式**: 负责计算下次运行时间并更新 `Cron` 调度器，触发链式运行。
#### B. `ExptEnd`: 通用的物理终结

这是所有实验运行结束后的必经之路，负责“打扫战场”。当调度器检测到 `toSubmit == 0` 且 `incomplete == 0` 时，意味着所有任务均已完结，会走到下面的逻辑

1.  **运行归档 (`CompleteRun`)**:
    *   **统计最终结果**: 再次全量扫描 `expt_turn_result`，计算最终的 `SuccessCnt` 和 `FailCnt`。
    *   **更新日志**: 将 `expt_run_log` 的状态更新为 `Success` 或 `Failed`
    *   **释放分布式锁**: 解除 `expt_mutex_lock:{ExptID}`，允许该实验被再次发起。
2.  **实验结单 (`CompleteExpt`)**:
    *   更新 `experiment` 主表状态：
        *   若所有 Item 均成功 -> `Success`
        *   若存在 Fail Item -> `Success` (注意：业务上部分失败也算实验完成，除非全挂)
    *   记录 `EndTime`。
3.  **资源释放 (Quota Release)**:
    *   调用 `RateLimiter` 归还占用的并发配额。
4.  **后置计算 (Post-Processing)**:
    *   触发 **离线聚合计算 (AggrCalculate)**：异步计算 P90 耗时、平均分、Token 消耗等聚合指标，存入 `expt_result_aggr` 表供报表展示。

---

## 4. Worker 执行机制详解 (Worker Mechanism)

Worker 是真正执行评估任务的单元，通过消费 MQ 中的 `ExptItemEvalEvent` 消息来驱动。其内部采用 **责任链 (Middleware Chain)** 模式包裹核心业务逻辑，并实现了细粒度的任务拆分与状态管理。

### 4.1 责任链架构 (Middleware Chain)

1.  **`HandleEventErr` (异常护盾与重试)**
    *   **Panic Recover**: 捕获 Panic，防止单任务崩溃 Worker 进程。
    *   **Retry Decision**: 捕获下层返回的 `error`。如果不为空，查询配置判断是否需要重试（`RetryTimes < MaxRetry`）。
        *   若需重试：直接发布新的 MQ 消息（`RetryTimes+1`），当前处理直接结束（保持 DB 状态为 `Processing` 不变）。
        *   若不重试：将错误透传给下层（最终在 `CompleteItemRun` 中标记为 Fail）。

2.  **`HandleEventCheck` (状态守门员)**
    *   **Pre-Check**: 在开跑前，先查一下 `expt_run_log` 的状态。
    *   **Fast Fail**: 如果实验已被用户取消 (`Terminated`)，直接返回 nil (Ack)，不再执行后续昂贵的模型调用。

3.  **`HandleEventLock` (幂等控制)**
    *   **Lock**: 尝试获取分布式锁 `lock:expt:item:{RunID}:{ItemID}`。
    *   **Idempotency**: 若抢锁失败，说明该任务正在被另一个 Worker 执行（MQ 重复投递），当前请求静默丢弃。

4.  **`HandleEventExec` (业务入口)**
    *   **Eval**: 调用内部 `eval()` 方法，开始真正的评估流程。

### 4.2 Item 级执行流程 (`eval` & `ExptItemEvalCtxExecutor`)

核心逻辑位于 `ExptItemEvalCtxExecutor.Eval`，它将一个 Item 的执行拆分为三个阶段：

#### A: 上下文构建与预处理 (`PreEval`)

在真正执行前，必须确保数据库里“有坑位”。

1.  **构建 Context (`eiec`)**: 加载实验配置 (`Expt`)、数据集内容 (`EvalSetItem`) 和现有运行日志 (`ExistItemEvalResult`)。
2.  **模式策略 (Strategy Pattern)**:
    *   **`Submit/Append` 模式**: 检查数据集定义的 Turns，对比库表`expt_turn_result_run_log`。如果发现库里缺记录，则使用 `BatchCreateNX` 批量插入状态为 `Processing` 的 `expt_turn_result_run_log`。
    *   **`FailRetry` 模式**: 基于主表 (`expt_turn_result`) 的上一次结果，全量克隆并生成新的 RunLog，状态重置为 `Processing`。
    *   **目的**: 确保 `EvalTurns` 阶段总是能从 `eiec` 中拿到已初始化的 Log 对象，实现“先占坑后填空”。

> [!TIP] 关于失败重跑模式
> 失败重跑模式克隆的是**上一次的结果**，除了主表的内容以外，还克隆了上一次结果的 `evaluationVersionId` 到 `ResultId` 的映射（如果有）。这个映射在后续 `EvalTurns` 中会被检查（虽然被封装为了其他对象，但是本质还是这个），如果发现有这个映射，那么就说明之前跑过，跳过对应的LLM调用的步骤

#### B: 循环执行 Turns (`EvalTurns`)

遍历数据集中的每一个 Turn (支持多轮对话)：

1.  **构建 TurnContext**: 将 Item 级上下文 + 历史对话 (`history`) 封装为 Turn 级上下文(`etec`)。
2.  **断点恢复**: 检查 `etec` 中是否已有 `TargetResultID` 或 `EvaluatorResultIDs`。如果有，说明之前跑过，直接跳过对应的执行步骤（Reentrancy）。
3.  **执行 (Eval)**: 调用 `NewExptTurnEvaluation(...).Eval` 执行模型和评分。
4.  **即时落库 (`storeTurnRunResult`)**:
    *   每跑完一个 Turn，立刻将结果元数据（`TargetResultID`, `EvaluatorResultIDs`, `Status`）更新到 `expt_turn_result_run_log`。
    *   **关键**: 此时 Item 级的状态仍为 `Processing`，Scheduler 不会收割。
5.  **上下文传递**: 将本轮的问答结果追加到 `history`，供下一轮使用。

#### C: 收尾与交卷 (`CompleteItemRun`)
当所有 Turn 都跑完（或遇到不可重试的错误）时：
1.  **计算最终状态**: 成功则 `Status=Success`，失败则 `Status=Fail`。
2.  **发出信号**: 更新 `expt_item_result_run_log`：
    *   `status`: 最终业务状态。
    *   **`result_state`: `Logged`** (核心信号)。
3.  **作用**: Scheduler 扫描到 `Logged` 状态后，便知道该 Item 已完结，可以进行主表同步和归档了。

---

## 5. 数据库架构与状态机 (DB Schema & State Machine)

### 5.1 数据流转全景图

```text
[ API 层: Create/Run/Retry ]
       |
       +--- (1) INSERT [expt_run_log] (状态: Pending) 
       |                                                                   
[ 调度器 (Scheduler) - ExptStart 初始化 ]                                  
       |                                                                   
       +--- (2) UPSERT [expt_item_result] & [expt_turn_result] (Status: Queueing)                        
       +--- (3) INSERT [expt_item_result_run_log] (Status: Queueing)                        
       +--- (4) 初始化 [ClickHouse] (Status: Queueing)                      
       |                                                                   
[ 调度器 (Scheduler) - 循环调度周期 ] <-----------------------------------------------------+
       |                                                                                  |
       +--- (5) 任务扫描与清理 (Scan & Cleanup) ---------------------------+                |
       |    |                                                             |                | (NextTick)
       |    +--> [清理僵尸] 检查 Processing 任务是否超时                    |                |
       |    |    - 若超时: 强置为 Fail 并转入 "待收割" 队列                 |                |
       |    |                                                             |                |
       |    +--> [任务分类] 扫描 [expt_item_result_run_log] 并按状态归类:   |                |
       |         - Queueing -> 进入 "待分发" 队列                          |                |
       |         - Logged   -> 进入 "待收割" 队列                          |                |
       |                                                                  |                |
       +--- (6) 任务分发 (Dispatch) -----------------------------------+   |                |
       |    - UPDATE [expt_item_result_run_log] -> Processing          |   |                |
       |    - UPDATE [expt_item_result] & [expt_turn_result] -> Processing |                |
       |    - 更新 [expt_stats] & [ClickHouse] & 发送 MQ                |   |                |
       |                                                               |   |                |
       +--- (7) 收割归档 (Archive) <-----------------------------------+---+                |
       |    - 从 [expt_turn_result_run_log] 同步回答/分数至 [expt_turn_result]              |
       |    - 更新 [expt_stats/ClickHouse] & UPDATE [expt_item_result_run_log] -> Resulted |
       |                                                                                  |
[ 执行器 (Worker) ] <---------------------------------------------------------------------+
       |
       +--- (8) PreEval 预处理
       |    - 检查/对比 [expt_turn_result_run_log]
       |    - INSERT [expt_turn_result_run_log] (Status: Processing) -> 确保每轮对话都有坑位
       |
       +--- (9) Turn Loop
       |    - (Inner) INSERT [eval_target_record] (模型回答详情) -> 拿到 TargetResultID
       |    - (Inner) INSERT [evaluator_record] (评分详情) -> 拿到 EvaluatorResultIDs
       |    - UPDATE [expt_turn_result_run_log] (填空: 填入上述 IDs, Status: Success/Fail)
       |
       +--- (10) CompleteItemRun
            - UPDATE [expt_item_result_run_log] (Status: Success/Fail, ResultState: Logged) ---+

[ 完结阶段 (Finalize) ]
       |
       +--- (11) UPDATE [experiment] (最终状态: Success/Failed)
       +--- (12) UPDATE [expt_run_log] (归档统计数据 & 释放锁)

```

### 5.2 核心状态机流转

系统维护了两套平行的状态机：一套用于**内部调度控制** (RunLog)，一套用于**外部结果展示** (Main Table)。

| 阶段 (Phase) | 动作触发者 | 流水表 `expt_item_result_run_log` <br> (驱动调度) | 主表 `expt_item_result` & `expt_turn_result` <br> (驱动 UI) | 关键行为 |
| :--- | :--- | :--- | :--- | :--- |
| **1. Init** | Scheduler | `Status: Queueing` <br> `ResultState: Init` | `Status: Queueing` | 占坑初始化。此时 ClickHouse 也被同步为 Queueing。 |
| **2. Dispatch** | Scheduler | `Status: Processing` <br> `ResultState: Init` | `Status: Processing` | 任务分发进 MQ。UI 变更为“运行中”。 |
| **3. Worker Done** | Worker | `Status: Success/Fail` <br> **`ResultState: Logged`** | `Status: Processing` | **关键中间态**。Worker 已交卷，但主表未更新。调度器扫描到 `Logged` 信号。 |
| **4. Archive** | Scheduler | `Status: Success/Fail` <br> **`ResultState: Resulted`** | **`Status: Success/Fail`** | 收割归档。将 Worker 的回答/分数同步到主表，UI 展示最终结果。 |

> [!TIP] **补充说明**:
> *   `expt_turn_result_run_log` (Turn详情流水): 仅在 **Stage 3 (Worker Done)** 被 Worker 插入一条记录。它是“结果数据”而非“状态数据”，不参与状态机流转。
> *   `ResultState`: 是调度器内部专用的“握手信号”。
>     *   `Init`: 初始/处理中。
>     *   `Logged`: Worker 喊你来搬砖。
>     *   `Resulted`: 搬砖结束，本轮翻篇。

## 6. 限流策略

1. 在同一个 RunID 内，Schedule 也不是一把梭全部扫出来，而是分成了三波：
	1. 扫描 `Processing`: 为了计算当前还在跑的任务数，判断是否达到了并发上限 (ItemConcurNum)。
	2. 扫描 `Queueing` (带 Limit): 如果并发还没满，按需扫出 submitCnt 数量的任务准备下发。这是一个滑动窗口，不是全量拉取，有效减轻了 DB 压力。
	3. 扫描 `Logged`: 专门找那些“Worker 跑完了等收割”的任务进行归档。

## 7. 其他思考

>  为什么要用两个字段来做状态机呢，不能只用`state`吗，如果要表示`worker done`再加多一个状态不就好了。

从理论上讲，我们完全可以在 `Status` 字段里加一个枚举值，比如 `Status_WorkerFinished` 来替代 `ResultState`。但在高并发离线系统中，拆分设计是出于深层考虑：

1. **语义解耦 (业务 vs 系统)**
*   **`Status` (Success/Fail)**: 代表**业务结果**。Worker 跑完那一刻，它已经明确知道自己是成功还是失败了，不应该因为“数据还没同步”就掩盖这个事实。
*   **`ResultState` (Logged/Resulted)**: 代表**数据搬运进度**。这是调度器的内部工作标记。

**如果合二为一的后果**：
假设 Worker 跑失败了，如果只有 `Status`：
*   若标 `Fail`：调度器无法区分这是“刚出炉的 Fail”还是“已归档的旧 Fail”。
*   若标 `Processing_Done`：那就丢失了“我是因为失败而结束”这个业务含义。

**拆分后**：Worker 可以标记 `Status=Fail` + `ResultState=Logged`。调度器一看便知：“哦，是个失败的任务，且我还没收割。”

2. 索引优化与性能
*   调度器最高频的操作是 `Scan`。
*   拆分后，调度器只需要扫描 `ResultState != Resulted` 的活跃记录。
*   归档完的任务变成 `Resulted`，永远退出扫描范围。如果不拆分，随着历史数据堆积，索引过滤条件会变得非常复杂且低效。

3. 支持复杂扩展

	未来如果业务变复杂，比如一个任务分三个阶段（流式输出）：

	- 第1秒：`Status=Processing`, `ResultState=Logged` (输出了一半，喊调度器同步一下)
	- 调度器：同步完，设 `ResultState=Init` (继续等下一波)
	- 第3秒：`Status=Success`, `ResultState=Logged` (全完了)

拆分字段让“业务状态”和“同步信号”可以独立变化，互不锁死。

>  现阶段，如果数据集都是一条一条的，即当前数据集全是单轮对话，那么 `expt_turn_result_run_log` 与 `expt_item_result_run_log` 的拆分是不是没有意义

1. **性能优化：“控制流”与“数据流”分离 (最重要)**

  这是数据库设计中典型的瘦表 (Thin Table) vs 胖表 (Fat Table) 策略。

   * `expt_item_result_run_log` (瘦表 - 控制面)
       * 用途: 供调度器高频 Scan。
       * 特点: 字段少，主要是状态 (Status, ResultState) 和时间戳。
       * 优势: 行记录非常小。InnoDB 的一页 (Page) 能存更多行。调度器在扫描 Processing 或 Queueing 任务时，IO
         效率极高，占用的内存 Buffer Pool 也少。

   * `expt_turn_result_run_log` (胖表 - 数据面)
       * 用途: 存储业务详情。
       * 特点: 包含大量的长文本（Prompt、Response、Debug Log、JSON Blob）。单行数据可能达到 KB 甚至 MB 级别。
       * 优势: 这些数据只有在“归档”那一刻才会被读取一次。

  如果合并的后果：
  
  如果把几十 KB 的回答内容塞到 `item_run_log` 里，虽然调度器 `SELECT` 时可以只查 `Status`
  字段，但数据库引擎在底层加载数据页时，依然会因为行体积过大导致缓存命中率下降，严重的会拖慢整个调度循环的吞吐量。



## 8. 枚举值

``` go

const (  
    ItemRunState_Unknown ItemRunState = -1  
    // Queuing  
    ItemRunState_Queueing ItemRunState = 0  
    // Processing  
    ItemRunState_Processing ItemRunState = 1  
    // Success  
    ItemRunState_Success ItemRunState = 2  
    // Failure  
    ItemRunState_Fail ItemRunState = 3  
    // Terminated  
    ItemRunState_Terminal ItemRunState = 5  
)

const (  
    // Not started  
    TurnRunState_Queueing TurnRunState = 0  
    // Execution succeeded  
    TurnRunState_Success TurnRunState = 1  
    // Execution failed  
    TurnRunState_Fail TurnRunState = 2  
    // In progress  
    TurnRunState_Processing TurnRunState = 3  
    // Terminated  
    TurnRunState_Terminal TurnRunState = 4  
)

const (  
    ExptItemResultStateDefault  ExptItemResultState = 0  
    ExptItemResultStateLogged   ExptItemResultState = 2  
    ExptItemResultStateResulted ExptItemResultState = 1  
)

const (  
    ExptStatus_Unknown ExptStatus = 0  
    // Awaiting execution  
    ExptStatus_Pending ExptStatus = 2  
    // In progress  
    ExptStatus_Processing ExptStatus = 3  
    // Execution succeeded  
    ExptStatus_Success ExptStatus = 11  
    // Execution failed  
    ExptStatus_Failed ExptStatus = 12  
    // User terminated  
    ExptStatus_Terminated ExptStatus = 13  
    // System terminated  
    ExptStatus_SystemTerminated ExptStatus = 14  
    ExptStatus_Terminating      ExptStatus = 15  
  
    // 流式执行完成，不再接收新的请求  
    ExptStatus_Draining ExptStatus = 21  
)

```
